# 5.1 Data Preparation - Fine-tuning Pipeline

## Descripción General

La preparación de datos es el paso más crítico del fine-tuning. Involucra selección, filtrado, formateo y validación de datos de entrenamiento.

## Arquitectura

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                       DATA PREPARATION PIPELINE                              │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐ │
│  │   Extract   │───▶│   Filter    │───▶│   Format    │───▶│  Validate   │ │
│  │             │    │             │    │             │    │             │ │
│  │ - Feedback  │    │ - Quality   │    │ - JSONL     │    │ - Schema    │ │
│  │ - Messages  │    │ - Sentiment │    │ - Chat      │    │ - Tokens    │ │
│  │ - Patterns  │    │ - Diversity │    │ - System    │    │ - Balance   │ │
│  └─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘ │
│                                                                              │
│  Output: training.jsonl (OpenAI Fine-tuning Format)                         │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

## Data Extractor

```typescript
// lib/ai-learning/finetuning/data-preparation/extractor.ts

import { createClient } from '@/lib/supabase/server';

interface RawConversation {
  id: string;
  messages: Array<{
    role: 'user' | 'assistant';
    content: string;
    metadata: Record<string, any>;
  }>;
  feedback: Array<{
    rating: number;
    comment?: string;
    dimension?: string;
  }>;
  metadata: Record<string, any>;
}

interface ExtractionConfig {
  tenantId: string;
  startDate: Date;
  endDate: Date;
  minMessages: number;
  requirePositiveFeedback: boolean;
  includeIntents: string[];
  excludeIntents: string[];
}

export class DataExtractor {
  /**
   * Extrae conversaciones candidatas para fine-tuning
   */
  async extractConversations(config: ExtractionConfig): Promise<RawConversation[]> {
    const supabase = await createClient();

    // Query conversaciones con feedback positivo
    let query = supabase
      .from('ai_conversations')
      .select(`
        id,
        metadata,
        created_at,
        ai_messages (
          role,
          content,
          metadata,
          created_at
        ),
        ai_feedback (
          rating,
          comment,
          dimension
        )
      `)
      .eq('tenant_id', config.tenantId)
      .gte('created_at', config.startDate.toISOString())
      .lt('created_at', config.endDate.toISOString())
      .order('created_at', { ascending: false });

    const { data, error } = await query;
    if (error) throw error;

    // Filtrar y mapear
    const conversations: RawConversation[] = [];

    for (const row of data || []) {
      const messages = (row.ai_messages || [])
        .sort((a: any, b: any) =>
          new Date(a.created_at).getTime() - new Date(b.created_at).getTime()
        )
        .map((m: any) => ({
          role: m.role,
          content: m.content,
          metadata: m.metadata || {},
        }));

      // Verificar mínimo de mensajes
      if (messages.length < config.minMessages) continue;

      const feedback = (row.ai_feedback || []).map((f: any) => ({
        rating: f.rating,
        comment: f.comment,
        dimension: f.dimension,
      }));

      // Verificar feedback positivo si es requerido
      if (config.requirePositiveFeedback) {
        const hasPositive = feedback.some(f => f.rating > 0);
        if (!hasPositive) continue;
      }

      // Filtrar por intents
      const conversationIntent = row.metadata?.primary_intent;
      if (config.includeIntents.length > 0 &&
          !config.includeIntents.includes(conversationIntent)) {
        continue;
      }
      if (config.excludeIntents.includes(conversationIntent)) {
        continue;
      }

      conversations.push({
        id: row.id,
        messages,
        feedback,
        metadata: row.metadata || {},
      });
    }

    return conversations;
  }

  /**
   * Extrae patrones de alta calidad
   */
  async extractPatterns(
    tenantId: string,
    minConfidence: number = 0.8
  ): Promise<Array<{
    intent: string;
    examples: string[];
    response_template: string;
  }>> {
    const supabase = await createClient();

    const { data } = await supabase
      .from('ai_patterns')
      .select('*')
      .eq('tenant_id', tenantId)
      .gte('confidence', minConfidence)
      .eq('status', 'active');

    return (data || []).map(p => ({
      intent: p.intent,
      examples: p.examples || [],
      response_template: p.response_template,
    }));
  }
}
```

## Quality Filter

```typescript
// lib/ai-learning/finetuning/data-preparation/filter.ts

interface FilterConfig {
  minMessageLength: number;
  maxMessageLength: number;
  minResponseQuality: number;
  requireResolution: boolean;
  excludePII: boolean;
  diversityThreshold: number;
}

interface FilteredConversation {
  id: string;
  messages: Array<{ role: string; content: string }>;
  qualityScore: number;
  intent: string;
}

export class QualityFilter {
  private config: FilterConfig;

  constructor(config: Partial<FilterConfig> = {}) {
    this.config = {
      minMessageLength: 10,
      maxMessageLength: 4000,
      minResponseQuality: 0.7,
      requireResolution: true,
      excludePII: true,
      diversityThreshold: 0.3,
      ...config,
    };
  }

  /**
   * Filtra conversaciones por calidad
   */
  filter(conversations: any[]): FilteredConversation[] {
    const filtered: FilteredConversation[] = [];
    const seenContents = new Set<string>();

    for (const conv of conversations) {
      // Calcular score de calidad
      const qualityScore = this.calculateQualityScore(conv);

      if (qualityScore < this.config.minResponseQuality) continue;

      // Verificar longitudes
      const validLengths = conv.messages.every((m: any) =>
        m.content.length >= this.config.minMessageLength &&
        m.content.length <= this.config.maxMessageLength
      );
      if (!validLengths) continue;

      // Verificar resolución
      if (this.config.requireResolution) {
        const resolved = conv.metadata?.resolved ||
                        conv.feedback?.some((f: any) => f.rating > 0);
        if (!resolved) continue;
      }

      // Filtrar PII
      if (this.config.excludePII) {
        const hasPII = conv.messages.some((m: any) => this.containsPII(m.content));
        if (hasPII) continue;
      }

      // Verificar diversidad (evitar duplicados)
      const contentHash = this.hashContent(conv.messages);
      if (seenContents.has(contentHash)) continue;
      seenContents.add(contentHash);

      filtered.push({
        id: conv.id,
        messages: conv.messages.map((m: any) => ({
          role: m.role,
          content: m.content,
        })),
        qualityScore,
        intent: conv.metadata?.primary_intent || 'general',
      });
    }

    return filtered;
  }

  /**
   * Calcula score de calidad de una conversación
   */
  private calculateQualityScore(conv: any): number {
    let score = 0.5; // Base score

    // Bonus por feedback positivo
    const positiveFeedback = conv.feedback?.filter((f: any) => f.rating > 0).length || 0;
    const negativeFeedback = conv.feedback?.filter((f: any) => f.rating < 0).length || 0;
    score += (positiveFeedback - negativeFeedback) * 0.1;

    // Bonus por conversación completa
    const hasUserMessage = conv.messages.some((m: any) => m.role === 'user');
    const hasAssistantMessage = conv.messages.some((m: any) => m.role === 'assistant');
    if (hasUserMessage && hasAssistantMessage) score += 0.2;

    // Bonus por metadata de confianza
    const confidence = conv.metadata?.avg_confidence || 0.5;
    score += (confidence - 0.5) * 0.2;

    // Penalizar por escalación
    if (conv.metadata?.escalated) score -= 0.2;

    return Math.max(0, Math.min(1, score));
  }

  /**
   * Detecta PII básico
   */
  private containsPII(text: string): boolean {
    const patterns = [
      /\b\d{3}[-.]?\d{3}[-.]?\d{4}\b/, // Phone
      /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/, // Email
      /\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b/, // Credit card
      /\b\d{3}[-\s]?\d{2}[-\s]?\d{4}\b/, // SSN (US)
    ];

    return patterns.some(pattern => pattern.test(text));
  }

  /**
   * Hash para deduplicación
   */
  private hashContent(messages: any[]): string {
    const content = messages.map(m => m.content).join('|');
    return Buffer.from(content).toString('base64').slice(0, 64);
  }
}
```

## JSONL Formatter

```typescript
// lib/ai-learning/finetuning/data-preparation/formatter.ts

interface FormatterConfig {
  systemPrompt: string;
  maxTokens: number;
  includeMetadata: boolean;
}

interface ChatMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface TrainingExample {
  messages: ChatMessage[];
}

export class JSONLFormatter {
  private config: FormatterConfig;

  constructor(config: Partial<FormatterConfig> = {}) {
    this.config = {
      systemPrompt: 'You are a helpful AI assistant for TIS TIS, specializing in appointment scheduling and customer service.',
      maxTokens: 4096,
      includeMetadata: false,
      ...config,
    };
  }

  /**
   * Formatea conversaciones a formato JSONL para OpenAI
   */
  format(conversations: any[]): string {
    const examples: TrainingExample[] = [];

    for (const conv of conversations) {
      const example = this.formatConversation(conv);
      if (example) {
        examples.push(example);
      }
    }

    // Convertir a JSONL (una línea JSON por ejemplo)
    return examples.map(e => JSON.stringify(e)).join('\n');
  }

  /**
   * Formatea una conversación individual
   */
  private formatConversation(conv: any): TrainingExample | null {
    const messages: ChatMessage[] = [
      {
        role: 'system',
        content: this.buildSystemPrompt(conv),
      },
    ];

    for (const msg of conv.messages) {
      if (msg.role === 'user') {
        messages.push({
          role: 'user',
          content: msg.content,
        });
      } else if (msg.role === 'assistant') {
        messages.push({
          role: 'assistant',
          content: msg.content,
        });
      }
    }

    // Verificar que termine con assistant
    if (messages[messages.length - 1].role !== 'assistant') {
      return null;
    }

    // Verificar tokens (aproximación)
    const totalChars = messages.reduce((sum, m) => sum + m.content.length, 0);
    const estimatedTokens = Math.ceil(totalChars / 4);

    if (estimatedTokens > this.config.maxTokens) {
      return null;
    }

    return { messages };
  }

  /**
   * Construye system prompt contextualizado
   */
  private buildSystemPrompt(conv: any): string {
    let prompt = this.config.systemPrompt;

    if (this.config.includeMetadata && conv.intent) {
      prompt += `\n\nContext: This conversation is about ${conv.intent}.`;
    }

    return prompt;
  }

  /**
   * Genera múltiples variaciones de entrenamiento
   */
  generateVariations(conv: any): TrainingExample[] {
    const variations: TrainingExample[] = [];

    // Variación original
    const original = this.formatConversation(conv);
    if (original) variations.push(original);

    // Variación con system prompt alternativo
    if (conv.messages.length >= 4) {
      // Tomar solo los primeros turns
      const shortened = {
        ...conv,
        messages: conv.messages.slice(0, 4),
      };
      const shortVariation = this.formatConversation(shortened);
      if (shortVariation) variations.push(shortVariation);
    }

    return variations;
  }
}
```

## Data Preparation Service

```typescript
// lib/ai-learning/finetuning/data-preparation/service.ts

import { DataExtractor } from './extractor';
import { QualityFilter } from './filter';
import { JSONLFormatter } from './formatter';
import { createClient } from '@/lib/supabase/server';

interface DatasetConfig {
  tenantId: string;
  startDate: Date;
  endDate: Date;
  minExamples: number;
  maxExamples: number;
  trainSplit: number;
  systemPrompt?: string;
}

interface DatasetResult {
  trainFile: string;
  validationFile: string;
  stats: {
    totalExtracted: number;
    afterFiltering: number;
    trainExamples: number;
    validationExamples: number;
    intentDistribution: Record<string, number>;
  };
}

export class DataPreparationService {
  private extractor: DataExtractor;
  private filter: QualityFilter;
  private formatter: JSONLFormatter;

  constructor() {
    this.extractor = new DataExtractor();
    this.filter = new QualityFilter();
    this.formatter = new JSONLFormatter();
  }

  /**
   * Prepara dataset completo para fine-tuning
   */
  async prepareDataset(config: DatasetConfig): Promise<DatasetResult> {
    // 1. Extraer conversaciones
    const raw = await this.extractor.extractConversations({
      tenantId: config.tenantId,
      startDate: config.startDate,
      endDate: config.endDate,
      minMessages: 2,
      requirePositiveFeedback: true,
      includeIntents: [],
      excludeIntents: ['complaint', 'escalation'],
    });

    // 2. Filtrar por calidad
    const filtered = this.filter.filter(raw);

    // 3. Balancear por intent
    const balanced = this.balanceByIntent(
      filtered,
      config.maxExamples
    );

    // 4. Split train/validation
    const shuffled = this.shuffle([...balanced]);
    const splitIndex = Math.floor(shuffled.length * config.trainSplit);
    const trainData = shuffled.slice(0, splitIndex);
    const validationData = shuffled.slice(splitIndex);

    // 5. Formatear a JSONL
    if (config.systemPrompt) {
      this.formatter = new JSONLFormatter({ systemPrompt: config.systemPrompt });
    }

    const trainFile = this.formatter.format(trainData);
    const validationFile = this.formatter.format(validationData);

    // 6. Calcular estadísticas
    const intentDistribution: Record<string, number> = {};
    for (const conv of balanced) {
      intentDistribution[conv.intent] = (intentDistribution[conv.intent] || 0) + 1;
    }

    return {
      trainFile,
      validationFile,
      stats: {
        totalExtracted: raw.length,
        afterFiltering: filtered.length,
        trainExamples: trainData.length,
        validationExamples: validationData.length,
        intentDistribution,
      },
    };
  }

  /**
   * Balancea ejemplos por intent
   */
  private balanceByIntent(
    data: any[],
    maxTotal: number
  ): any[] {
    // Agrupar por intent
    const byIntent = new Map<string, any[]>();
    for (const item of data) {
      if (!byIntent.has(item.intent)) {
        byIntent.set(item.intent, []);
      }
      byIntent.get(item.intent)!.push(item);
    }

    // Calcular ejemplos por intent
    const numIntents = byIntent.size;
    const maxPerIntent = Math.ceil(maxTotal / numIntents);

    // Tomar máximo balanceado de cada intent
    const balanced: any[] = [];
    for (const [intent, items] of byIntent) {
      const shuffled = this.shuffle([...items]);
      balanced.push(...shuffled.slice(0, maxPerIntent));
    }

    return balanced.slice(0, maxTotal);
  }

  private shuffle<T>(array: T[]): T[] {
    for (let i = array.length - 1; i > 0; i--) {
      const j = Math.floor(Math.random() * (i + 1));
      [array[i], array[j]] = [array[j], array[i]];
    }
    return array;
  }

  /**
   * Guarda dataset en storage
   */
  async saveDataset(
    tenantId: string,
    datasetName: string,
    result: DatasetResult
  ): Promise<{ trainUrl: string; validationUrl: string }> {
    const supabase = await createClient();
    const timestamp = Date.now();

    // Subir archivos a storage
    const trainPath = `finetuning/${tenantId}/${datasetName}_train_${timestamp}.jsonl`;
    const validationPath = `finetuning/${tenantId}/${datasetName}_validation_${timestamp}.jsonl`;

    await supabase.storage
      .from('ai-datasets')
      .upload(trainPath, result.trainFile, {
        contentType: 'application/jsonl',
      });

    await supabase.storage
      .from('ai-datasets')
      .upload(validationPath, result.validationFile, {
        contentType: 'application/jsonl',
      });

    // Registrar dataset
    await supabase.from('ai_finetuning_datasets').insert({
      tenant_id: tenantId,
      name: datasetName,
      train_file_path: trainPath,
      validation_file_path: validationPath,
      stats: result.stats,
      status: 'ready',
    });

    const { data: trainData } = await supabase.storage
      .from('ai-datasets')
      .createSignedUrl(trainPath, 3600);

    const { data: validationData } = await supabase.storage
      .from('ai-datasets')
      .createSignedUrl(validationPath, 3600);

    return {
      trainUrl: trainData?.signedUrl || '',
      validationUrl: validationData?.signedUrl || '',
    };
  }
}
```

## Siguiente Documento

Continúa con [5.2-TRAINING-PIPELINE.md](./5.2-TRAINING-PIPELINE.md) para la implementación del pipeline de entrenamiento.
