# 6.2 Evidence Extractor - Explainability (XAI)

## Descripción General

El Evidence Extractor identifica y resalta las partes del input y contexto que más influyeron en una decisión del AI.

## Evidence Extractor Service

```typescript
// lib/ai-learning/xai/evidence-extractor.ts

import OpenAI from 'openai';
import { createClient } from '@/lib/supabase/server';

interface EvidenceItem {
  type: 'text_span' | 'feature' | 'pattern' | 'history';
  content: string;
  relevance: number; // 0-1
  startIndex?: number;
  endIndex?: number;
  explanation: string;
}

interface ExtractionResult {
  decisionLogId: string;
  evidenceItems: EvidenceItem[];
  summary: string;
  confidence: number;
}

export class EvidenceExtractor {
  private openai: OpenAI;

  constructor() {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
  }

  /**
   * Extrae evidencia para una decisión loggeada
   */
  async extractEvidence(decisionLogId: string): Promise<ExtractionResult> {
    const supabase = await createClient();

    // Obtener log de decisión
    const { data: log } = await supabase
      .from('ai_decision_logs')
      .select('*')
      .eq('id', decisionLogId)
      .single();

    if (!log) throw new Error('Decision log not found');

    const evidenceItems: EvidenceItem[] = [];

    // Extraer evidencia del texto de input
    if (log.input_text) {
      const textEvidence = await this.extractTextEvidence(
        log.input_text,
        log.decision,
        log.decision_type
      );
      evidenceItems.push(...textEvidence);
    }

    // Extraer evidencia de features
    if (log.input_features) {
      const featureEvidence = this.extractFeatureEvidence(
        log.input_features,
        log.influence_factors
      );
      evidenceItems.push(...featureEvidence);
    }

    // Extraer evidencia de candidatos
    if (log.candidates) {
      const candidateEvidence = this.extractCandidateEvidence(log.candidates, log.decision);
      evidenceItems.push(...candidateEvidence);
    }

    // Ordenar por relevancia
    evidenceItems.sort((a, b) => b.relevance - a.relevance);

    // Generar resumen
    const summary = await this.generateSummary(evidenceItems, log);

    // Guardar evidencia
    await supabase.from('ai_decision_evidence').insert({
      decision_log_id: decisionLogId,
      evidence_items: evidenceItems,
      summary,
      confidence: this.calculateConfidence(evidenceItems),
    });

    return {
      decisionLogId,
      evidenceItems,
      summary,
      confidence: this.calculateConfidence(evidenceItems),
    };
  }

  /**
   * Extrae spans relevantes del texto
   */
  private async extractTextEvidence(
    text: string,
    decision: string,
    decisionType: string
  ): Promise<EvidenceItem[]> {
    const prompt = `
Analyze this text and identify the key phrases/spans that would lead to the decision "${decision}" for a ${decisionType} task.

Text: "${text}"

For each relevant span, provide:
1. The exact text span
2. Why it's relevant (brief explanation)
3. Relevance score (0-1)

Respond in JSON format:
{
  "spans": [
    {
      "text": "<exact span>",
      "explanation": "<why relevant>",
      "relevance": <0-1>
    }
  ]
}
`;

    const response = await this.openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{ role: 'user', content: prompt }],
      response_format: { type: 'json_object' },
    });

    const result = JSON.parse(response.choices[0]?.message?.content || '{"spans":[]}');

    return (result.spans || []).map((span: any) => {
      const startIndex = text.indexOf(span.text);
      return {
        type: 'text_span' as const,
        content: span.text,
        relevance: span.relevance,
        startIndex: startIndex >= 0 ? startIndex : undefined,
        endIndex: startIndex >= 0 ? startIndex + span.text.length : undefined,
        explanation: span.explanation,
      };
    });
  }

  /**
   * Extrae evidencia de features
   */
  private extractFeatureEvidence(
    features: Record<string, any>,
    influenceFactors?: any[]
  ): EvidenceItem[] {
    const items: EvidenceItem[] = [];

    // Usar influence factors si están disponibles
    if (influenceFactors && influenceFactors.length > 0) {
      for (const factor of influenceFactors) {
        items.push({
          type: 'feature',
          content: `${factor.factor}: ${factor.value}`,
          relevance: Math.abs(factor.contribution),
          explanation: `This factor contributed ${(factor.contribution * 100).toFixed(1)}% to the decision`,
        });
      }
    } else {
      // Extraer features significativos
      for (const [key, value] of Object.entries(features)) {
        if (value !== null && value !== undefined) {
          items.push({
            type: 'feature',
            content: `${key}: ${JSON.stringify(value)}`,
            relevance: 0.5, // Default
            explanation: `Feature "${key}" was considered in the decision`,
          });
        }
      }
    }

    return items;
  }

  /**
   * Extrae evidencia de candidatos considerados
   */
  private extractCandidateEvidence(candidates: any[], finalDecision: string): EvidenceItem[] {
    return candidates.slice(0, 5).map(candidate => ({
      type: 'pattern' as const,
      content: candidate.option,
      relevance: candidate.score,
      explanation: candidate.option === finalDecision
        ? `Selected option with score ${(candidate.score * 100).toFixed(1)}%`
        : `Alternative considered: ${candidate.reasoning || `score ${(candidate.score * 100).toFixed(1)}%`}`,
    }));
  }

  /**
   * Genera resumen de la evidencia
   */
  private async generateSummary(evidenceItems: EvidenceItem[], log: any): Promise<string> {
    const topEvidence = evidenceItems.slice(0, 5);

    const prompt = `
Summarize why the AI made this decision in 2-3 sentences for a non-technical user.

Decision Type: ${log.decision_type}
Decision Made: ${log.decision}
Confidence: ${(log.confidence * 100).toFixed(1)}%

Key Evidence:
${topEvidence.map(e => `- ${e.content}: ${e.explanation}`).join('\n')}

Write a clear, simple explanation.
`;

    const response = await this.openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 200,
    });

    return response.choices[0]?.message?.content || 'Unable to generate summary.';
  }

  private calculateConfidence(evidenceItems: EvidenceItem[]): number {
    if (evidenceItems.length === 0) return 0;

    const avgRelevance = evidenceItems.reduce((sum, e) => sum + e.relevance, 0) / evidenceItems.length;
    const hasHighRelevance = evidenceItems.some(e => e.relevance > 0.8);

    return hasHighRelevance ? Math.min(avgRelevance + 0.1, 1) : avgRelevance;
  }

  /**
   * Obtiene evidencia para un decision log
   */
  async getEvidence(decisionLogId: string): Promise<ExtractionResult | null> {
    const supabase = await createClient();

    const { data } = await supabase
      .from('ai_decision_evidence')
      .select('*')
      .eq('decision_log_id', decisionLogId)
      .single();

    if (!data) return null;

    return {
      decisionLogId: data.decision_log_id,
      evidenceItems: data.evidence_items,
      summary: data.summary,
      confidence: data.confidence,
    };
  }
}
```

## Schema

```sql
CREATE TABLE ai_decision_evidence (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  decision_log_id UUID NOT NULL REFERENCES ai_decision_logs(id) ON DELETE CASCADE,
  evidence_items JSONB NOT NULL,
  summary TEXT NOT NULL,
  confidence FLOAT NOT NULL,
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  UNIQUE(decision_log_id)
);

CREATE INDEX idx_evidence_decision ON ai_decision_evidence(decision_log_id);
```

## Siguiente Documento

Continúa con [6.3-AUDIT-TRAIL.md](./6.3-AUDIT-TRAIL.md) para el sistema de audit trail.
