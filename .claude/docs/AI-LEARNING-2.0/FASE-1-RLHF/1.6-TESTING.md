# ðŸ§ª FASE 1.6: Testing del Sistema RLHF

## Microfase de Pruebas y ValidaciÃ³n

**Documento:** 1.6-TESTING.md
**Fase:** 1 - RLHF (Reinforcement Learning from Human Feedback)
**DuraciÃ³n estimada:** 1-1.5 semanas
**Dependencias:** 1.1-1.5 (Todo el sistema RLHF)

---

## ðŸ“‹ Ãndice

1. [Estrategia de Testing](#estrategia-de-testing)
2. [Unit Tests](#unit-tests)
3. [Integration Tests](#integration-tests)
4. [E2E Tests](#e2e-tests)
5. [Performance Tests](#performance-tests)
6. [Test Data Fixtures](#test-data-fixtures)
7. [CI/CD Pipeline](#cicd-pipeline)
8. [Checklist de ValidaciÃ³n](#checklist-de-validaciÃ³n)

---

## ðŸŽ¯ Estrategia de Testing

### PirÃ¡mide de Tests

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   E2E     â”‚  5%  - Flujos crÃ­ticos completos
                    â”‚   Tests   â”‚
                 â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”
                 â”‚  Integration    â”‚  25% - APIs, DB, servicios
                 â”‚     Tests       â”‚
              â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”
              â”‚      Unit Tests       â”‚  70% - Funciones, componentes
              â”‚                       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Coverage Goals

| Componente | Target Coverage | Prioridad |
|------------|-----------------|-----------|
| Statistical Utils | 95% | Alta |
| Feedback Service | 90% | Alta |
| Aggregator Service | 85% | Alta |
| Optimizer Service | 85% | Alta |
| UI Components | 80% | Media |
| API Routes | 80% | Media |

### Testing Stack

```typescript
// package.json - Dev dependencies
{
  "devDependencies": {
    "vitest": "^1.2.0",
    "@testing-library/react": "^14.1.0",
    "@testing-library/user-event": "^14.5.0",
    "msw": "^2.0.0",
    "@faker-js/faker": "^8.3.0",
    "supertest": "^6.3.0"
  }
}
```

---

## ðŸ”¬ Unit Tests

### Archivo: `src/features/ai/rlhf/__tests__/statistics.utils.test.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Statistical Utils Unit Tests
// Tests para funciones estadÃ­sticas del sistema RLHF
// =====================================================

import { describe, it, expect } from 'vitest';
import {
  wilsonScoreInterval,
  calculateWeightedSatisfaction,
  detectTrend,
  getPeriodBoundaries,
  groupByDimension,
  getTopNegativeReasons,
} from '../utils/statistics.utils';

describe('wilsonScoreInterval', () => {
  it('should return 0 bounds for empty data', () => {
    const result = wilsonScoreInterval(0, 0);
    expect(result.lower).toBe(0);
    expect(result.upper).toBe(0);
    expect(result.center).toBe(0);
  });

  it('should calculate correct interval for 50% success rate', () => {
    const result = wilsonScoreInterval(50, 100);
    expect(result.center).toBeCloseTo(0.5, 1);
    expect(result.lower).toBeGreaterThan(0.4);
    expect(result.upper).toBeLessThan(0.6);
  });

  it('should have wider interval for smaller samples', () => {
    const smallSample = wilsonScoreInterval(5, 10);
    const largeSample = wilsonScoreInterval(50, 100);

    const smallWidth = smallSample.upper - smallSample.lower;
    const largeWidth = largeSample.upper - largeSample.lower;

    expect(smallWidth).toBeGreaterThan(largeWidth);
  });

  it('should handle 100% success rate', () => {
    const result = wilsonScoreInterval(100, 100);
    expect(result.center).toBeGreaterThan(0.95);
    expect(result.lower).toBeGreaterThan(0.9);
    expect(result.upper).toBe(1);
  });

  it('should handle 0% success rate', () => {
    const result = wilsonScoreInterval(0, 100);
    expect(result.center).toBeLessThan(0.05);
    expect(result.lower).toBe(0);
    expect(result.upper).toBeLessThan(0.1);
  });
});

describe('calculateWeightedSatisfaction', () => {
  it('should return 0.5 (neutral) for no feedback', () => {
    const result = calculateWeightedSatisfaction(0, 0, 0, 0);
    expect(result).toBe(0.5);
  });

  it('should return 1.0 for all positive feedback', () => {
    const result = calculateWeightedSatisfaction(100, 0, 0, 0);
    expect(result).toBe(1.0);
  });

  it('should return 0.0 for all negative with reason', () => {
    const result = calculateWeightedSatisfaction(0, 0, 100, 0);
    expect(result).toBe(0.0);
  });

  it('should weight negative with reason more heavily', () => {
    const withReason = calculateWeightedSatisfaction(50, 0, 50, 0);
    const withoutReason = calculateWeightedSatisfaction(50, 50, 0, 0);

    expect(withoutReason).toBeGreaterThan(withReason);
  });

  it('should handle mixed feedback correctly', () => {
    // 60 positive, 20 simple negative, 15 with reason, 5 with correction
    const result = calculateWeightedSatisfaction(60, 20, 15, 5);
    expect(result).toBeGreaterThan(0.4);
    expect(result).toBeLessThan(0.7);
  });
});

describe('detectTrend', () => {
  it('should detect improving trend', () => {
    const result = detectTrend(0.8, 0.6, 0.5);
    expect(result.direction).toBe('improving');
    expect(result.magnitude).toBeGreaterThan(0);
    expect(result.confidence).toBeGreaterThan(0.7);
  });

  it('should detect declining trend', () => {
    const result = detectTrend(0.4, 0.6, 0.7);
    expect(result.direction).toBe('declining');
    expect(result.magnitude).toBeLessThan(0);
  });

  it('should detect stable trend', () => {
    const result = detectTrend(0.7, 0.71, 0.69);
    expect(result.direction).toBe('stable');
    expect(Math.abs(result.magnitude)).toBeLessThan(0.05);
  });

  it('should detect volatile trend', () => {
    const result = detectTrend(0.8, 0.4, 0.7);
    expect(result.direction).toBe('volatile');
    expect(result.confidence).toBeLessThan(0.7);
  });

  it('should use custom threshold', () => {
    // With default threshold (0.05), this would be stable
    const withDefault = detectTrend(0.7, 0.74, 0.72, 0.05);
    expect(withDefault.direction).toBe('stable');

    // With lower threshold (0.01), this should be improving
    const withLower = detectTrend(0.7, 0.68, 0.65, 0.01);
    expect(withLower.direction).toBe('improving');
  });
});

describe('getPeriodBoundaries', () => {
  it('should return 24h boundaries', () => {
    const { start, end } = getPeriodBoundaries('24h');
    const diffHours = (end.getTime() - start.getTime()) / (1000 * 60 * 60);
    expect(diffHours).toBeCloseTo(24, 0);
  });

  it('should return 7d boundaries', () => {
    const { start, end } = getPeriodBoundaries('7d');
    const diffDays = (end.getTime() - start.getTime()) / (1000 * 60 * 60 * 24);
    expect(diffDays).toBeCloseTo(7, 0);
  });

  it('should return 30d boundaries', () => {
    const { start, end } = getPeriodBoundaries('30d');
    const diffDays = (end.getTime() - start.getTime()) / (1000 * 60 * 60 * 24);
    expect(diffDays).toBeCloseTo(30, 0);
  });
});

describe('groupByDimension', () => {
  it('should group items by dimension', () => {
    const items = [
      { id: 1, type: 'A' },
      { id: 2, type: 'B' },
      { id: 3, type: 'A' },
      { id: 4, type: 'A' },
    ];

    const groups = groupByDimension(items, 'type');

    expect(groups.get('A')?.length).toBe(3);
    expect(groups.get('B')?.length).toBe(1);
  });

  it('should handle missing dimension values', () => {
    const items = [
      { id: 1, type: 'A' },
      { id: 2 },
      { id: 3, type: 'A' },
    ];

    const groups = groupByDimension(items as any[], 'type');

    expect(groups.get('A')?.length).toBe(2);
    expect(groups.get('unknown')?.length).toBe(1);
  });

  it('should return empty map for empty input', () => {
    const groups = groupByDimension([], 'type');
    expect(groups.size).toBe(0);
  });
});

describe('getTopNegativeReasons', () => {
  it('should return top N reasons sorted by count', () => {
    const feedback = [
      { feedback_reason: 'Slow response' },
      { feedback_reason: 'Wrong info' },
      { feedback_reason: 'Slow response' },
      { feedback_reason: 'Slow response' },
      { feedback_reason: 'Rude tone' },
      { feedback_reason: 'Wrong info' },
    ];

    const top = getTopNegativeReasons(feedback, 2);

    expect(top.length).toBe(2);
    expect(top[0].reason).toBe('Slow response');
    expect(top[0].count).toBe(3);
    expect(top[1].reason).toBe('Wrong info');
    expect(top[1].count).toBe(2);
  });

  it('should calculate percentages correctly', () => {
    const feedback = [
      { feedback_reason: 'A' },
      { feedback_reason: 'A' },
      { feedback_reason: 'B' },
      { feedback_reason: 'B' },
    ];

    const top = getTopNegativeReasons(feedback);

    expect(top[0].percentage).toBe(50);
    expect(top[1].percentage).toBe(50);
  });

  it('should ignore null reasons', () => {
    const feedback = [
      { feedback_reason: 'A' },
      { feedback_reason: null },
      { feedback_reason: 'A' },
      { feedback_reason: null },
    ];

    const top = getTopNegativeReasons(feedback);

    expect(top.length).toBe(1);
    expect(top[0].count).toBe(2);
    expect(top[0].percentage).toBe(100); // 2 out of 2 with reasons
  });

  it('should return empty array for no feedback with reasons', () => {
    const feedback = [
      { feedback_reason: null },
      { feedback_reason: null },
    ];

    const top = getTopNegativeReasons(feedback);
    expect(top.length).toBe(0);
  });
});
```

### Archivo: `src/features/ai/rlhf/__tests__/statistical-analyzer.test.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Statistical Analyzer Unit Tests
// Tests para el analizador Bayesiano de A/B tests
// =====================================================

import { describe, it, expect, beforeEach } from 'vitest';
import { StatisticalAnalyzer } from '../experiments/statistical-analyzer';

describe('StatisticalAnalyzer', () => {
  let analyzer: StatisticalAnalyzer;

  beforeEach(() => {
    analyzer = new StatisticalAnalyzer({
      numSimulations: 1000, // Lower for faster tests
      minSamplesForDecision: 50,
      confidenceThreshold: 0.95,
    });
  });

  describe('analyzeExperiment', () => {
    it('should return continue recommendation for small samples', () => {
      const result = analyzer.analyzeExperiment('exp_1', [
        { variant_id: 'control', impressions: 10, positive_feedback: 7 },
        { variant_id: 'variant_a', impressions: 10, positive_feedback: 8 },
      ]);

      expect(result.recommendation).toBe('continue');
      expect(result.winner).toBeNull();
    });

    it('should detect clear winner with sufficient data', () => {
      const result = analyzer.analyzeExperiment('exp_1', [
        { variant_id: 'control', impressions: 500, positive_feedback: 250 },
        { variant_id: 'variant_a', impressions: 500, positive_feedback: 400 },
      ]);

      expect(result.winner).toBe('variant_a');
      expect(result.confidence).toBeGreaterThan(0.9);
      expect(result.recommendation).toBe('stop_winner');
    });

    it('should recommend stop_no_winner when variants are similar', () => {
      const result = analyzer.analyzeExperiment('exp_1', [
        { variant_id: 'control', impressions: 500, positive_feedback: 350 },
        { variant_id: 'variant_a', impressions: 500, positive_feedback: 355 },
      ]);

      expect(result.recommendation).toBe('stop_no_winner');
    });

    it('should calculate conversion rates correctly', () => {
      const result = analyzer.analyzeExperiment('exp_1', [
        { variant_id: 'control', impressions: 100, positive_feedback: 70 },
        { variant_id: 'variant_a', impressions: 100, positive_feedback: 80 },
      ]);

      const control = result.variants.find(v => v.variant_id === 'control');
      const variantA = result.variants.find(v => v.variant_id === 'variant_a');

      expect(control?.conversion_rate).toBe(0.7);
      expect(variantA?.conversion_rate).toBe(0.8);
    });

    it('should calculate probability_best that sums to ~1', () => {
      const result = analyzer.analyzeExperiment('exp_1', [
        { variant_id: 'control', impressions: 200, positive_feedback: 100 },
        { variant_id: 'variant_a', impressions: 200, positive_feedback: 120 },
        { variant_id: 'variant_b', impressions: 200, positive_feedback: 110 },
      ]);

      const sumProbability = result.variants.reduce(
        (sum, v) => sum + v.probability_best,
        0
      );

      expect(sumProbability).toBeCloseTo(1, 1);
    });

    it('should calculate expected loss', () => {
      const result = analyzer.analyzeExperiment('exp_1', [
        { variant_id: 'control', impressions: 200, positive_feedback: 100 },
        { variant_id: 'variant_a', impressions: 200, positive_feedback: 160 },
      ]);

      const control = result.variants.find(v => v.variant_id === 'control');
      const variantA = result.variants.find(v => v.variant_id === 'variant_a');

      // Control should have higher expected loss (it's worse)
      expect(control?.expected_loss).toBeGreaterThan(variantA?.expected_loss ?? 0);
    });

    it('should provide credible intervals', () => {
      const result = analyzer.analyzeExperiment('exp_1', [
        { variant_id: 'control', impressions: 100, positive_feedback: 70 },
      ]);

      const control = result.variants[0];

      expect(control.credible_interval[0]).toBeLessThan(0.7);
      expect(control.credible_interval[1]).toBeGreaterThan(0.7);
      expect(control.credible_interval[0]).toBeGreaterThan(0);
      expect(control.credible_interval[1]).toBeLessThan(1);
    });
  });

  describe('edge cases', () => {
    it('should handle zero impressions', () => {
      const result = analyzer.analyzeExperiment('exp_1', [
        { variant_id: 'control', impressions: 0, positive_feedback: 0 },
        { variant_id: 'variant_a', impressions: 100, positive_feedback: 70 },
      ]);

      expect(result.recommendation).toBe('continue');
    });

    it('should handle 100% conversion rate', () => {
      const result = analyzer.analyzeExperiment('exp_1', [
        { variant_id: 'control', impressions: 100, positive_feedback: 100 },
        { variant_id: 'variant_a', impressions: 100, positive_feedback: 90 },
      ]);

      expect(result.variants[0].conversion_rate).toBe(1);
    });

    it('should handle single variant', () => {
      const result = analyzer.analyzeExperiment('exp_1', [
        { variant_id: 'control', impressions: 100, positive_feedback: 70 },
      ]);

      expect(result.variants[0].probability_best).toBe(1);
    });
  });
});
```

### Archivo: `src/features/ai/rlhf/__tests__/variant-generator.test.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Variant Generator Unit Tests
// Tests para el generador de variantes de prompts
// =====================================================

import { describe, it, expect, vi, beforeEach } from 'vitest';
import { VariantGenerator } from '../experiments/variant-generator';

// Mock Google AI
vi.mock('@google/generative-ai', () => ({
  GoogleGenerativeAI: vi.fn().mockImplementation(() => ({
    getGenerativeModel: vi.fn().mockReturnValue({
      generateContent: vi.fn().mockResolvedValue({
        response: {
          text: () => JSON.stringify({
            variants: [
              {
                variant_name: 'variant_ai_1',
                template: 'Improved template...',
                changes_description: 'Added empathy',
                hypothesis: 'Better tone will improve satisfaction',
              },
            ],
          }),
        },
      }),
    }),
  })),
}));

describe('VariantGenerator', () => {
  let generator: VariantGenerator;

  beforeEach(() => {
    generator = new VariantGenerator();
  });

  describe('generateVariants - template strategy', () => {
    it('should generate template-based variants', async () => {
      const variants = await generator.generateVariants({
        base_prompt_id: 'response.scheduling',
        strategy: 'template',
        weakness_context: {
          low_satisfaction_areas: [],
          common_complaints: [],
          user_corrections: [],
        },
        num_variants: 2,
      });

      expect(variants.length).toBeLessThanOrEqual(2);
      expect(variants[0]).toHaveProperty('variant_name');
      expect(variants[0]).toHaveProperty('template');
      expect(variants[0]).toHaveProperty('changes_description');
      expect(variants[0]).toHaveProperty('hypothesis');
    });

    it('should preserve template variables', async () => {
      const variants = await generator.generateVariants({
        base_prompt_id: 'response.scheduling',
        strategy: 'template',
        weakness_context: {
          low_satisfaction_areas: [],
          common_complaints: [],
          user_corrections: [],
        },
        num_variants: 1,
      });

      // Should still contain variable placeholders
      expect(variants[0].template).toMatch(/\{\{.*\}\}/);
    });
  });

  describe('generateVariants - ai_assisted strategy', () => {
    it('should generate AI-assisted variants', async () => {
      const variants = await generator.generateVariants({
        base_prompt_id: 'response.scheduling',
        strategy: 'ai_assisted',
        weakness_context: {
          low_satisfaction_areas: ['tone'],
          common_complaints: ['Too formal'],
          user_corrections: ['Should be more friendly'],
        },
        num_variants: 1,
      });

      expect(variants.length).toBe(1);
      expect(variants[0].variant_name).toContain('ai');
    });
  });

  describe('generateVariants - feedback_driven strategy', () => {
    it('should fall back to AI when no corrections available', async () => {
      const variants = await generator.generateVariants({
        base_prompt_id: 'response.scheduling',
        strategy: 'feedback_driven',
        weakness_context: {
          low_satisfaction_areas: [],
          common_complaints: [],
          user_corrections: [], // Empty
        },
        num_variants: 1,
      });

      // Should still generate something (fallback to AI)
      expect(variants.length).toBe(1);
    });
  });

  describe('error handling', () => {
    it('should throw for unknown prompt ID', async () => {
      await expect(
        generator.generateVariants({
          base_prompt_id: 'nonexistent.prompt',
          strategy: 'template',
          weakness_context: {
            low_satisfaction_areas: [],
            common_complaints: [],
            user_corrections: [],
          },
          num_variants: 1,
        })
      ).rejects.toThrow('Base prompt not found');
    });
  });
});
```

---

## ðŸ”— Integration Tests

### Archivo: `src/features/ai/rlhf/__tests__/feedback-service.integration.test.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Feedback Service Integration Tests
// Tests de integraciÃ³n para el servicio de feedback
// =====================================================

import { describe, it, expect, beforeAll, afterAll, beforeEach } from 'vitest';
import { createClient } from '@supabase/supabase-js';
import { FeedbackCaptureService } from '../services/feedback-capture.service';
import { generateTestTenant, generateTestFeedback, cleanupTestData } from './fixtures/test-helpers';

describe('FeedbackCaptureService Integration', () => {
  let service: FeedbackCaptureService;
  let supabase: ReturnType<typeof createClient>;
  let testTenantId: string;

  beforeAll(async () => {
    // Use test database
    supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!
    );

    // Create test tenant
    const tenant = await generateTestTenant(supabase);
    testTenantId = tenant.id;

    service = new FeedbackCaptureService();
  });

  afterAll(async () => {
    await cleanupTestData(supabase, testTenantId);
  });

  beforeEach(async () => {
    // Clean feedback before each test
    await supabase
      .from('ai_rlhf_feedback')
      .delete()
      .eq('tenant_id', testTenantId);
  });

  describe('captureFeedback', () => {
    it('should capture positive feedback', async () => {
      const feedback = generateTestFeedback({
        tenant_id: testTenantId,
        feedback_type: 'positive',
      });

      const result = await service.captureFeedback(feedback);

      expect(result.success).toBe(true);
      expect(result.feedback_id).toBeDefined();

      // Verify in database
      const { data } = await supabase
        .from('ai_rlhf_feedback')
        .select('*')
        .eq('id', result.feedback_id)
        .single();

      expect(data?.feedback_type).toBe('positive');
    });

    it('should capture negative feedback with reason', async () => {
      const feedback = generateTestFeedback({
        tenant_id: testTenantId,
        feedback_type: 'negative',
        feedback_reason: 'wrong_information',
        feedback_text: 'The hours were incorrect',
      });

      const result = await service.captureFeedback(feedback);

      expect(result.success).toBe(true);

      const { data } = await supabase
        .from('ai_rlhf_feedback')
        .select('*')
        .eq('id', result.feedback_id)
        .single();

      expect(data?.feedback_reason).toBe('wrong_information');
      expect(data?.feedback_text).toBe('The hours were incorrect');
    });

    it('should capture feedback with expected response', async () => {
      const feedback = generateTestFeedback({
        tenant_id: testTenantId,
        feedback_type: 'negative',
        expected_response: 'Should have said: We are open until 8pm',
      });

      const result = await service.captureFeedback(feedback);

      expect(result.success).toBe(true);

      const { data } = await supabase
        .from('ai_rlhf_feedback')
        .select('*')
        .eq('id', result.feedback_id)
        .single();

      expect(data?.expected_response).toContain('8pm');
    });

    it('should enrich metadata with context', async () => {
      const feedback = generateTestFeedback({
        tenant_id: testTenantId,
        metadata: {
          pattern_type: 'scheduling',
          agent_node: 'booking_agent',
        },
      });

      const result = await service.captureFeedback(feedback);

      const { data } = await supabase
        .from('ai_rlhf_feedback')
        .select('*')
        .eq('id', result.feedback_id)
        .single();

      expect(data?.metadata?.pattern_type).toBe('scheduling');
      expect(data?.metadata?.agent_node).toBe('booking_agent');
    });

    it('should reject duplicate feedback within time window', async () => {
      const feedback = generateTestFeedback({ tenant_id: testTenantId });

      // First submission
      await service.captureFeedback(feedback);

      // Immediate duplicate
      const result = await service.captureFeedback(feedback);

      expect(result.success).toBe(false);
      expect(result.error).toContain('duplicate');
    });

    it('should enforce rate limiting', async () => {
      // Submit many feedbacks quickly
      const promises = Array.from({ length: 15 }, () =>
        service.captureFeedback(
          generateTestFeedback({ tenant_id: testTenantId })
        )
      );

      const results = await Promise.all(promises);
      const rateLimited = results.filter(r => r.error?.includes('rate'));

      expect(rateLimited.length).toBeGreaterThan(0);
    });
  });

  describe('getFeedbackStats', () => {
    it('should return correct stats', async () => {
      // Insert test data
      const feedbacks = [
        generateTestFeedback({ tenant_id: testTenantId, feedback_type: 'positive' }),
        generateTestFeedback({ tenant_id: testTenantId, feedback_type: 'positive' }),
        generateTestFeedback({ tenant_id: testTenantId, feedback_type: 'negative' }),
      ];

      for (const fb of feedbacks) {
        await service.captureFeedback(fb);
      }

      const stats = await service.getFeedbackStats(testTenantId, '7d');

      expect(stats.total_feedback).toBe(3);
      expect(stats.positive_count).toBe(2);
      expect(stats.negative_count).toBe(1);
      expect(stats.satisfaction_rate).toBeCloseTo(0.67, 1);
    });
  });
});
```

### Archivo: `src/features/ai/rlhf/__tests__/aggregator.integration.test.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Aggregator Integration Tests
// Tests de integraciÃ³n para el servicio de agregaciÃ³n
// =====================================================

import { describe, it, expect, beforeAll, afterAll, beforeEach } from 'vitest';
import { createClient } from '@supabase/supabase-js';
import { FeedbackAggregatorService } from '../services/feedback-aggregator.service';
import {
  generateTestTenant,
  generateTestFeedback,
  cleanupTestData,
  bulkInsertFeedback,
} from './fixtures/test-helpers';

describe('FeedbackAggregatorService Integration', () => {
  let aggregator: FeedbackAggregatorService;
  let supabase: ReturnType<typeof createClient>;
  let testTenantId: string;

  beforeAll(async () => {
    supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!
    );

    const tenant = await generateTestTenant(supabase);
    testTenantId = tenant.id;

    aggregator = new FeedbackAggregatorService({
      minSampleSize: 3, // Lower for testing
    });
  });

  afterAll(async () => {
    await cleanupTestData(supabase, testTenantId);
  });

  beforeEach(async () => {
    // Clean tables
    await supabase.from('ai_rlhf_feedback').delete().eq('tenant_id', testTenantId);
    await supabase.from('ai_rlhf_aggregated').delete().eq('tenant_id', testTenantId);
  });

  describe('aggregateForTenant', () => {
    it('should aggregate feedback by pattern_type', async () => {
      // Insert diverse feedback
      await bulkInsertFeedback(supabase, testTenantId, [
        { pattern_type: 'scheduling', feedback_type: 'positive', count: 7 },
        { pattern_type: 'scheduling', feedback_type: 'negative', count: 3 },
        { pattern_type: 'inquiry', feedback_type: 'positive', count: 8 },
        { pattern_type: 'inquiry', feedback_type: 'negative', count: 2 },
      ]);

      const result = await aggregator.aggregateForTenant(testTenantId);

      expect(result.success).toBe(true);
      expect(result.metrics_generated).toBeGreaterThan(0);

      // Verify aggregated data
      const { data: aggregated } = await supabase
        .from('ai_rlhf_aggregated')
        .select('*')
        .eq('tenant_id', testTenantId)
        .eq('dimension_type', 'pattern_type');

      expect(aggregated?.length).toBeGreaterThan(0);

      const schedulingAgg = aggregated?.find(a => a.dimension_value === 'scheduling');
      expect(schedulingAgg?.total_feedback).toBe(10);
      expect(schedulingAgg?.satisfaction_rate).toBeCloseTo(0.7, 1);
    });

    it('should calculate trend correctly with historical data', async () => {
      // Insert historical aggregation
      await supabase.from('ai_rlhf_aggregated').insert({
        tenant_id: testTenantId,
        dimension_type: 'pattern_type',
        dimension_value: 'scheduling',
        period: '7d',
        satisfaction_rate: 0.8,
        total_feedback: 50,
        aggregated_at: new Date(Date.now() - 7 * 24 * 60 * 60 * 1000).toISOString(),
      });

      // Insert current feedback with lower satisfaction
      await bulkInsertFeedback(supabase, testTenantId, [
        { pattern_type: 'scheduling', feedback_type: 'positive', count: 5 },
        { pattern_type: 'scheduling', feedback_type: 'negative', count: 5 },
      ]);

      await aggregator.aggregateForTenant(testTenantId);

      const { data: latest } = await supabase
        .from('ai_rlhf_aggregated')
        .select('*')
        .eq('tenant_id', testTenantId)
        .eq('dimension_value', 'scheduling')
        .order('aggregated_at', { ascending: false })
        .limit(1)
        .single();

      expect(latest?.trend_direction).toBe('declining');
    });

    it('should handle empty feedback gracefully', async () => {
      const result = await aggregator.aggregateForTenant(testTenantId);

      expect(result.success).toBe(true);
      expect(result.metrics_generated).toBe(0);
      expect(result.errors.length).toBe(0);
    });

    it('should skip dimensions with insufficient samples', async () => {
      // Insert only 2 feedbacks (below minSampleSize of 3)
      await bulkInsertFeedback(supabase, testTenantId, [
        { pattern_type: 'rare_type', feedback_type: 'positive', count: 2 },
      ]);

      const result = await aggregator.aggregateForTenant(testTenantId);

      const { data: aggregated } = await supabase
        .from('ai_rlhf_aggregated')
        .select('*')
        .eq('tenant_id', testTenantId)
        .eq('dimension_value', 'rare_type');

      expect(aggregated?.length).toBe(0);
    });
  });

  describe('getInsightsSummary', () => {
    it('should return meaningful insights', async () => {
      // Setup data with declining trend
      await bulkInsertFeedback(supabase, testTenantId, [
        { pattern_type: 'scheduling', feedback_type: 'positive', count: 40 },
        { pattern_type: 'scheduling', feedback_type: 'negative', count: 60 },
        { pattern_type: 'inquiry', feedback_type: 'positive', count: 80 },
        { pattern_type: 'inquiry', feedback_type: 'negative', count: 20 },
      ]);

      await aggregator.aggregateForTenant(testTenantId);

      const insights = await aggregator.getInsightsSummary(testTenantId);

      expect(insights.overall_satisfaction).toBeGreaterThan(0);
      expect(insights.top_improvement_areas.length).toBeGreaterThan(0);

      // Scheduling should be in improvement areas (low satisfaction)
      const schedulingArea = insights.top_improvement_areas.find(
        a => a.area.includes('scheduling')
      );
      expect(schedulingArea).toBeDefined();
    });
  });
});
```

---

## ðŸŒ E2E Tests

### Archivo: `src/features/ai/rlhf/__tests__/e2e/feedback-flow.e2e.test.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - E2E Test: Complete Feedback Flow
// Test end-to-end del flujo completo de feedback RLHF
// =====================================================

import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import { chromium, Browser, Page } from 'playwright';
import { createClient } from '@supabase/supabase-js';
import { generateTestTenant, cleanupTestData } from '../fixtures/test-helpers';

describe('E2E: RLHF Feedback Flow', () => {
  let browser: Browser;
  let page: Page;
  let supabase: ReturnType<typeof createClient>;
  let testTenantId: string;
  let authToken: string;

  beforeAll(async () => {
    browser = await chromium.launch();
    page = await browser.newPage();

    supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!
    );

    // Create test tenant and user
    const tenant = await generateTestTenant(supabase);
    testTenantId = tenant.id;

    // Login and get token
    const { data: auth } = await supabase.auth.signInWithPassword({
      email: 'test@example.com',
      password: 'testpassword123',
    });
    authToken = auth.session?.access_token ?? '';
  });

  afterAll(async () => {
    await cleanupTestData(supabase, testTenantId);
    await browser.close();
  });

  it('should complete full feedback submission flow', async () => {
    // 1. Navigate to chat interface
    await page.goto(`http://localhost:3000/chat?tenant=${testTenantId}`);

    // 2. Wait for AI response to appear
    await page.waitForSelector('[data-testid="ai-message"]', { timeout: 10000 });

    // 3. Click thumbs down on the response
    await page.click('[data-testid="feedback-button-negative"]');

    // 4. Wait for feedback modal
    await page.waitForSelector('[data-testid="feedback-modal"]');

    // 5. Select a reason
    await page.click('[data-testid="reason-wrong_information"]');

    // 6. Enter additional comment
    await page.fill(
      '[data-testid="feedback-comment"]',
      'The response mentioned wrong business hours'
    );

    // 7. Enter expected response
    await page.fill(
      '[data-testid="expected-response"]',
      'We are open Monday to Friday, 9am to 6pm'
    );

    // 8. Submit feedback
    await page.click('[data-testid="submit-feedback"]');

    // 9. Verify success message
    await page.waitForSelector('[data-testid="feedback-success"]');

    // 10. Verify feedback was saved in database
    const { data: feedback } = await supabase
      .from('ai_rlhf_feedback')
      .select('*')
      .eq('tenant_id', testTenantId)
      .order('created_at', { ascending: false })
      .limit(1)
      .single();

    expect(feedback).toBeDefined();
    expect(feedback?.feedback_type).toBe('negative');
    expect(feedback?.feedback_reason).toBe('wrong_information');
    expect(feedback?.expected_response).toContain('9am to 6pm');
  });

  it('should show positive feedback confirmation', async () => {
    await page.goto(`http://localhost:3000/chat?tenant=${testTenantId}`);
    await page.waitForSelector('[data-testid="ai-message"]');

    // Click thumbs up
    await page.click('[data-testid="feedback-button-positive"]');

    // Should show brief confirmation
    const toast = await page.waitForSelector('[data-testid="feedback-toast"]');
    const text = await toast.textContent();

    expect(text).toContain('Gracias');

    // Verify in database
    const { data: feedback } = await supabase
      .from('ai_rlhf_feedback')
      .select('*')
      .eq('tenant_id', testTenantId)
      .eq('feedback_type', 'positive')
      .order('created_at', { ascending: false })
      .limit(1)
      .single();

    expect(feedback).toBeDefined();
  });
});
```

---

## âš¡ Performance Tests

### Archivo: `src/features/ai/rlhf/__tests__/performance/aggregation.perf.test.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Performance Tests: Aggregation
// Tests de rendimiento para el sistema de agregaciÃ³n
// =====================================================

import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import { createClient } from '@supabase/supabase-js';
import { FeedbackAggregatorService } from '../../services/feedback-aggregator.service';
import { generateTestTenant, cleanupTestData } from '../fixtures/test-helpers';

describe('Performance: Aggregation Service', () => {
  let aggregator: FeedbackAggregatorService;
  let supabase: ReturnType<typeof createClient>;
  let testTenantId: string;

  beforeAll(async () => {
    supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!
    );

    const tenant = await generateTestTenant(supabase);
    testTenantId = tenant.id;

    aggregator = new FeedbackAggregatorService();

    // Seed large amount of test data
    await seedPerformanceData(supabase, testTenantId, 10000);
  });

  afterAll(async () => {
    await cleanupTestData(supabase, testTenantId);
  });

  it('should aggregate 10k feedbacks under 5 seconds', async () => {
    const start = Date.now();

    const result = await aggregator.aggregateForTenant(testTenantId);

    const duration = Date.now() - start;

    expect(result.success).toBe(true);
    expect(duration).toBeLessThan(5000);

    console.log(`Aggregation of 10k records: ${duration}ms`);
    console.log(`Metrics generated: ${result.metrics_generated}`);
  });

  it('should handle concurrent aggregation requests', async () => {
    const concurrentRequests = 5;
    const start = Date.now();

    const promises = Array.from({ length: concurrentRequests }, () =>
      aggregator.aggregateForTenant(testTenantId)
    );

    const results = await Promise.all(promises);

    const duration = Date.now() - start;

    // All should succeed
    expect(results.every(r => r.success)).toBe(true);

    // Should complete in reasonable time
    expect(duration).toBeLessThan(15000);

    console.log(`${concurrentRequests} concurrent aggregations: ${duration}ms`);
  });

  it('should have efficient memory usage', async () => {
    const before = process.memoryUsage().heapUsed;

    await aggregator.aggregateForTenant(testTenantId);

    const after = process.memoryUsage().heapUsed;
    const memoryIncrease = (after - before) / 1024 / 1024;

    // Should not use more than 100MB
    expect(memoryIncrease).toBeLessThan(100);

    console.log(`Memory increase: ${memoryIncrease.toFixed(2)}MB`);
  });
});

// Helper to seed large dataset
async function seedPerformanceData(
  supabase: ReturnType<typeof createClient>,
  tenantId: string,
  count: number
): Promise<void> {
  const batchSize = 1000;
  const patternTypes = ['scheduling', 'inquiry', 'complaint', 'feedback', 'other'];
  const agentNodes = ['router', 'booking', 'info', 'support'];

  for (let i = 0; i < count; i += batchSize) {
    const batch = Array.from({ length: Math.min(batchSize, count - i) }, () => ({
      tenant_id: tenantId,
      message_id: `perf_msg_${i}_${Math.random().toString(36).substr(2, 9)}`,
      conversation_id: `perf_conv_${Math.floor(Math.random() * 100)}`,
      feedback_type: Math.random() > 0.3 ? 'positive' : 'negative',
      feedback_reason: Math.random() > 0.5 ? 'wrong_information' : null,
      metadata: {
        pattern_type: patternTypes[Math.floor(Math.random() * patternTypes.length)],
        agent_node: agentNodes[Math.floor(Math.random() * agentNodes.length)],
      },
      created_at: new Date(Date.now() - Math.random() * 30 * 24 * 60 * 60 * 1000).toISOString(),
    }));

    await supabase.from('ai_rlhf_feedback').insert(batch);
  }
}
```

---

## ðŸ“¦ Test Data Fixtures

### Archivo: `src/features/ai/rlhf/__tests__/fixtures/test-helpers.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Test Helpers and Fixtures
// Utilidades y datos de prueba para tests RLHF
// =====================================================

import { faker } from '@faker-js/faker';
import type { SupabaseClient } from '@supabase/supabase-js';

// ==================== Tenant Helpers ====================

export async function generateTestTenant(supabase: SupabaseClient) {
  const tenantId = `test_${faker.string.alphanumeric(8)}`;

  const { data, error } = await supabase
    .from('tenants')
    .insert({
      id: tenantId,
      name: `Test Tenant ${tenantId}`,
      slug: tenantId,
      vertical: 'dental',
      plan: 'essentials',
      settings: {},
    })
    .select()
    .single();

  if (error) throw error;

  // Enable AI learning for tenant
  await supabase.from('ai_learning_config').insert({
    tenant_id: tenantId,
    learning_enabled: true,
  });

  return data;
}

export async function cleanupTestData(supabase: SupabaseClient, tenantId: string) {
  // Clean in order to respect foreign keys
  await supabase.from('ai_prompt_experiments').delete().eq('tenant_id', tenantId);
  await supabase.from('ai_rlhf_aggregated').delete().eq('tenant_id', tenantId);
  await supabase.from('ai_rlhf_feedback').delete().eq('tenant_id', tenantId);
  await supabase.from('ai_learning_config').delete().eq('tenant_id', tenantId);
  await supabase.from('tenants').delete().eq('id', tenantId);
}

// ==================== Feedback Helpers ====================

interface FeedbackOptions {
  tenant_id: string;
  feedback_type?: 'positive' | 'negative';
  feedback_reason?: string | null;
  feedback_text?: string | null;
  expected_response?: string | null;
  metadata?: Record<string, unknown>;
}

export function generateTestFeedback(options: FeedbackOptions) {
  return {
    tenant_id: options.tenant_id,
    message_id: `msg_${faker.string.alphanumeric(10)}`,
    conversation_id: `conv_${faker.string.alphanumeric(8)}`,
    user_message: faker.lorem.sentence(),
    ai_response: faker.lorem.paragraph(),
    feedback_type: options.feedback_type ?? 'positive',
    feedback_reason: options.feedback_reason ?? null,
    feedback_text: options.feedback_text ?? null,
    expected_response: options.expected_response ?? null,
    metadata: options.metadata ?? {
      pattern_type: faker.helpers.arrayElement(['scheduling', 'inquiry', 'complaint']),
      agent_node: faker.helpers.arrayElement(['router', 'booking', 'info']),
      response_time_ms: faker.number.int({ min: 100, max: 2000 }),
    },
  };
}

// ==================== Bulk Insert Helpers ====================

interface BulkFeedbackConfig {
  pattern_type: string;
  feedback_type: 'positive' | 'negative';
  count: number;
  reason?: string;
}

export async function bulkInsertFeedback(
  supabase: SupabaseClient,
  tenantId: string,
  configs: BulkFeedbackConfig[]
): Promise<void> {
  const feedbacks: ReturnType<typeof generateTestFeedback>[] = [];

  for (const config of configs) {
    for (let i = 0; i < config.count; i++) {
      feedbacks.push(
        generateTestFeedback({
          tenant_id: tenantId,
          feedback_type: config.feedback_type,
          feedback_reason: config.reason ?? null,
          metadata: {
            pattern_type: config.pattern_type,
          },
        })
      );
    }
  }

  // Insert in batches
  const batchSize = 100;
  for (let i = 0; i < feedbacks.length; i += batchSize) {
    const batch = feedbacks.slice(i, i + batchSize);
    await supabase.from('ai_rlhf_feedback').insert(batch);
  }
}

// ==================== Experiment Helpers ====================

export function generateTestExperiment(tenantId: string) {
  return {
    id: `exp_${faker.string.alphanumeric(10)}`,
    tenant_id: tenantId,
    name: `Test Experiment ${faker.word.adjective()}`,
    description: faker.lorem.sentence(),
    prompt_category: 'response',
    status: 'draft' as const,
    variants: [
      {
        variant_id: `var_control_${faker.string.alphanumeric(6)}`,
        variant_name: 'control',
        template: 'Original template...',
        is_control: true,
        traffic_percentage: 50,
      },
      {
        variant_id: `var_a_${faker.string.alphanumeric(6)}`,
        variant_name: 'variant_a',
        template: 'Modified template...',
        is_control: false,
        traffic_percentage: 50,
      },
    ],
    min_samples_per_variant: 50,
    start_date: new Date().toISOString(),
    created_at: new Date().toISOString(),
    updated_at: new Date().toISOString(),
  };
}

// ==================== Assertion Helpers ====================

export function expectWithinRange(value: number, min: number, max: number) {
  expect(value).toBeGreaterThanOrEqual(min);
  expect(value).toBeLessThanOrEqual(max);
}

export function expectApproximately(actual: number, expected: number, tolerance: number = 0.1) {
  expect(Math.abs(actual - expected)).toBeLessThanOrEqual(tolerance);
}
```

---

## ðŸ”„ CI/CD Pipeline

### Archivo: `.github/workflows/rlhf-tests.yml`

```yaml
name: RLHF Tests

on:
  push:
    branches: [main, develop]
    paths:
      - 'src/features/ai/rlhf/**'
      - 'app/api/rlhf/**'
  pull_request:
    branches: [main]
    paths:
      - 'src/features/ai/rlhf/**'
      - 'app/api/rlhf/**'

env:
  NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.TEST_SUPABASE_URL }}
  SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.TEST_SUPABASE_SERVICE_KEY }}
  GOOGLE_AI_API_KEY: ${{ secrets.GOOGLE_AI_API_KEY }}

jobs:
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run unit tests
        run: npm run test:unit -- --coverage --reporter=verbose src/features/ai/rlhf

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          flags: rlhf-unit

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run integration tests
        run: npm run test:integration -- src/features/ai/rlhf

  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: integration-tests
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright
        run: npx playwright install --with-deps chromium

      - name: Start dev server
        run: npm run dev &
        env:
          PORT: 3000

      - name: Wait for server
        run: npx wait-on http://localhost:3000

      - name: Run E2E tests
        run: npm run test:e2e -- src/features/ai/rlhf

      - name: Upload artifacts
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: playwright-report
          path: playwright-report/

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: integration-tests
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run performance tests
        run: npm run test:perf -- src/features/ai/rlhf

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const results = fs.readFileSync('./perf-results.json', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: '## Performance Test Results\n```json\n' + results + '\n```'
            });
```

---

## âœ… Checklist de ValidaciÃ³n

### Pre-launch Checklist

```
â–¡ Unit Tests
â”œâ”€â”€ [ ] statistics.utils.test.ts passing (100%)
â”œâ”€â”€ [ ] statistical-analyzer.test.ts passing (100%)
â”œâ”€â”€ [ ] variant-generator.test.ts passing (100%)
â”œâ”€â”€ [ ] feedback-capture.service.test.ts passing (100%)
â””â”€â”€ [ ] Coverage > 85%

â–¡ Integration Tests
â”œâ”€â”€ [ ] feedback-service.integration.test.ts passing
â”œâ”€â”€ [ ] aggregator.integration.test.ts passing
â”œâ”€â”€ [ ] optimizer.integration.test.ts passing
â””â”€â”€ [ ] All DB operations verified

â–¡ E2E Tests
â”œâ”€â”€ [ ] feedback-flow.e2e.test.ts passing
â”œâ”€â”€ [ ] experiment-flow.e2e.test.ts passing
â””â”€â”€ [ ] Cross-browser tested (Chrome, Firefox)

â–¡ Performance Tests
â”œâ”€â”€ [ ] 10k records < 5 seconds
â”œâ”€â”€ [ ] Memory usage < 100MB
â”œâ”€â”€ [ ] Concurrent requests handled
â””â”€â”€ [ ] No N+1 queries detected

â–¡ Security Tests
â”œâ”€â”€ [ ] RLS policies verified
â”œâ”€â”€ [ ] Rate limiting tested
â”œâ”€â”€ [ ] Input validation tested
â””â”€â”€ [ ] XSS prevention verified

â–¡ CI/CD
â”œâ”€â”€ [ ] GitHub Actions workflow configured
â”œâ”€â”€ [ ] All tests passing in CI
â”œâ”€â”€ [ ] Coverage reports uploading
â””â”€â”€ [ ] Performance baselines established
```

### Manual Testing Checklist

```
â–¡ Positive Feedback Flow
â”œâ”€â”€ [ ] Click ðŸ‘ shows confirmation
â”œâ”€â”€ [ ] Feedback saved in DB
â”œâ”€â”€ [ ] No duplicate submissions
â””â”€â”€ [ ] Animation smooth

â–¡ Negative Feedback Flow
â”œâ”€â”€ [ ] Click ðŸ‘Ž opens modal
â”œâ”€â”€ [ ] All reasons selectable
â”œâ”€â”€ [ ] Text input works
â”œâ”€â”€ [ ] Expected response field works
â”œâ”€â”€ [ ] Submit saves all data
â””â”€â”€ [ ] Cancel closes modal

â–¡ Aggregation
â”œâ”€â”€ [ ] Cron job runs on schedule
â”œâ”€â”€ [ ] Metrics calculated correctly
â”œâ”€â”€ [ ] Trends detected properly
â””â”€â”€ [ ] Dashboard shows data

â–¡ Experiments
â”œâ”€â”€ [ ] Can create experiment
â”œâ”€â”€ [ ] Traffic split works
â”œâ”€â”€ [ ] Metrics collected per variant
â”œâ”€â”€ [ ] Winner detection works
â””â”€â”€ [ ] Can promote winner
```

---

## ðŸ“ Notas Finales

### Testing Best Practices

1. **IsolaciÃ³n**: Cada test debe ser independiente
2. **Limpieza**: Always cleanup test data
3. **Fixtures**: Use consistent test data
4. **Mocking**: Mock external services (Google AI)
5. **Timeouts**: Set appropriate timeouts for async operations

### Debugging Tips

```bash
# Run single test file
npm run test -- src/features/ai/rlhf/__tests__/statistics.utils.test.ts

# Run with verbose logging
DEBUG=* npm run test

# Run only failed tests
npm run test -- --reporter=verbose --bail

# Generate coverage report
npm run test -- --coverage --reporter=html
```

### Known Test Limitations

1. **Bayesian tests**: Monte Carlo results may vary slightly
2. **E2E tests**: Require running server
3. **Performance tests**: Results depend on hardware

---

**FASE 1 COMPLETADA** âœ…

Siguiente: [FASE-2-EMBEDDINGS/2.0-OVERVIEW.md](../FASE-2-EMBEDDINGS/2.0-OVERVIEW.md)
