# ğŸ”§ FASE 1.5: Prompt Optimizer Service

## Microfase del Sistema de OptimizaciÃ³n de Prompts

**Documento:** 1.5-PROMPT-OPTIMIZER.md
**Fase:** 1 - RLHF (Reinforcement Learning from Human Feedback)
**DuraciÃ³n estimada:** 2-2.5 semanas
**Dependencias:** 1.4 (Aggregator)

---

## ğŸ“‹ Ãndice

1. [Objetivo](#objetivo)
2. [Arquitectura del Optimizer](#arquitectura-del-optimizer)
3. [Algoritmo de OptimizaciÃ³n](#algoritmo-de-optimizaciÃ³n)
4. [ImplementaciÃ³n del Servicio](#implementaciÃ³n-del-servicio)
5. [A/B Testing Framework](#ab-testing-framework)
6. [Integration con LangGraph](#integration-con-langgraph)
7. [Checklist de ImplementaciÃ³n](#checklist-de-implementaciÃ³n)

---

## ğŸ¯ Objetivo

El Prompt Optimizer usa mÃ©tricas agregadas de RLHF para mejorar automÃ¡ticamente los prompts del sistema. Implementa un ciclo de mejora continua basado en feedback real de usuarios.

### Ciclo de OptimizaciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PROMPT OPTIMIZATION CYCLE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚    â”‚  Aggregated  â”‚                                             â”‚
â”‚    â”‚  Metrics     â”‚                                             â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚           â”‚                                                      â”‚
â”‚           â–¼                                                      â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚    â”‚   Identify   â”‚â”€â”€â”€â”€â–ºâ”‚   Generate   â”‚                       â”‚
â”‚    â”‚   Weak Areas â”‚     â”‚   Variants   â”‚                       â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                â”‚                                 â”‚
â”‚                                â–¼                                 â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                         â”‚   A/B Test   â”‚                        â”‚
â”‚                         â”‚   Deployment â”‚                        â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                â”‚                                 â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚           â”‚                    â”‚                    â”‚            â”‚
â”‚           â–¼                    â–¼                    â–¼            â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚    â”‚ Variant  â”‚         â”‚ Variant  â”‚        â”‚ Control  â”‚       â”‚
â”‚    â”‚    A     â”‚         â”‚    B     â”‚        â”‚ (Base)   â”‚       â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                    â”‚                    â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                       â”‚   Collect    â”‚                          â”‚
â”‚                       â”‚   Feedback   â”‚                          â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                       â”‚  Statistical â”‚                          â”‚
â”‚                       â”‚   Analysis   â”‚                          â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                              â”‚                                   â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚               â”‚                             â”‚                    â”‚
â”‚               â–¼                             â–¼                    â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚        â”‚   Winner     â”‚            â”‚   No Clear   â”‚            â”‚
â”‚        â”‚   Found      â”‚            â”‚   Winner     â”‚            â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚               â”‚                           â”‚                     â”‚
â”‚               â–¼                           â–¼                     â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚        â”‚   Promote    â”‚            â”‚   Continue   â”‚            â”‚
â”‚        â”‚   to Prod    â”‚            â”‚   Testing    â”‚            â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Arquitectura del Optimizer

### Componentes

```
src/features/ai/rlhf/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ feedback-aggregator.service.ts  # âœ… De 1.4
â”‚   â””â”€â”€ prompt-optimizer.service.ts     # ğŸ†• Este documento
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ experiment-manager.ts           # ğŸ†• GestiÃ³n de experimentos
â”‚   â”œâ”€â”€ variant-generator.ts            # ğŸ†• GeneraciÃ³n de variantes
â”‚   â””â”€â”€ statistical-analyzer.ts         # ğŸ†• AnÃ¡lisis estadÃ­stico
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ base-prompts.ts                 # ğŸ†• Prompts base
â”‚   â””â”€â”€ prompt-registry.ts              # ğŸ†• Registro de prompts
â””â”€â”€ types/
    â””â”€â”€ optimizer.types.ts              # ğŸ†• Tipos para optimizaciÃ³n
```

### Flujo de Datos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ ai_rlhf_        â”‚         â”‚ ai_prompt_      â”‚                  â”‚
â”‚  â”‚ aggregated      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ experiments     â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                       â”‚                            â”‚
â”‚                                       â–¼                            â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                           â”‚  ExperimentManager  â”‚                 â”‚
â”‚                           â”‚                     â”‚                 â”‚
â”‚                           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                 â”‚
â”‚                           â”‚  â”‚ Active        â”‚  â”‚                 â”‚
â”‚                           â”‚  â”‚ Experiments   â”‚  â”‚                 â”‚
â”‚                           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                 â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                      â”‚                             â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                           â”‚                     â”‚                  â”‚
â”‚                           â–¼                     â–¼                  â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                    â”‚ LangGraph   â”‚       â”‚ Direct API  â”‚          â”‚
â”‚                    â”‚ Agents      â”‚       â”‚ Calls       â”‚          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Algoritmo de OptimizaciÃ³n

### 1. IdentificaciÃ³n de Ãreas DÃ©biles

```typescript
/**
 * Weakness Detection Algorithm
 *
 * Identifica prompts que necesitan mejora basado en:
 * 1. Satisfaction rate < threshold (default: 70%)
 * 2. Declining trend con alta confianza
 * 3. Alto volumen de feedback negativo con razones
 */

interface WeaknessIdentification {
  prompt_id: string;
  weakness_type: 'low_satisfaction' | 'declining_trend' | 'frequent_complaints';
  severity: 'critical' | 'high' | 'medium' | 'low';
  evidence: {
    metric_name: string;
    current_value: number;
    threshold: number;
    sample_size: number;
  }[];
  suggested_improvements: string[];
}
```

### 2. GeneraciÃ³n de Variantes

```typescript
/**
 * Variant Generation Strategies
 *
 * 1. Template-based: Modificaciones predefinidas
 * 2. AI-assisted: Usar LLM para sugerir mejoras
 * 3. Feedback-driven: Incorporar correcciones de usuarios
 */

type VariantStrategy = 'template' | 'ai_assisted' | 'feedback_driven';

interface PromptVariant {
  variant_id: string;
  base_prompt_id: string;
  strategy: VariantStrategy;
  changes: {
    type: 'tone' | 'structure' | 'content' | 'length';
    description: string;
    before: string;
    after: string;
  }[];
  hypothesis: string;
}
```

### 3. SelecciÃ³n de Ganador (A/B Testing)

```typescript
/**
 * Winner Selection using Bayesian A/B Testing
 *
 * Advantages over frequentist:
 * - Works with smaller sample sizes
 * - Provides probability of being best
 * - Allows early stopping
 */

interface ABTestResult {
  experiment_id: string;
  variants: Array<{
    variant_id: string;
    samples: number;
    conversions: number;  // positive feedback
    conversion_rate: number;
    probability_best: number;
    expected_loss: number;
  }>;
  winner: string | null;
  confidence: number;
  recommendation: 'continue' | 'stop_winner' | 'stop_no_winner';
}
```

---

## ğŸ’» ImplementaciÃ³n del Servicio

### Archivo: `src/features/ai/rlhf/types/optimizer.types.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Prompt Optimizer Types
// Tipos para el sistema de optimizaciÃ³n de prompts
// =====================================================

export type VariantStrategy = 'template' | 'ai_assisted' | 'feedback_driven';
export type ExperimentStatus = 'draft' | 'active' | 'paused' | 'completed' | 'archived';
export type WeaknessSeverity = 'critical' | 'high' | 'medium' | 'low';

export interface PromptDefinition {
  id: string;
  name: string;
  category: 'system' | 'agent' | 'response' | 'classification';
  template: string;
  variables: string[];
  version: number;
  created_at: string;
  updated_at: string;
}

export interface PromptVariant {
  variant_id: string;
  experiment_id: string;
  base_prompt_id: string;
  variant_name: string;  // 'control', 'variant_a', 'variant_b', etc.
  template: string;
  strategy: VariantStrategy;
  changes_description: string;
  hypothesis: string;
  traffic_percentage: number;
  is_control: boolean;
}

export interface ExperimentConfig {
  id: string;
  tenant_id: string;
  name: string;
  description: string;
  prompt_category: string;
  status: ExperimentStatus;
  variants: PromptVariant[];

  // Targeting
  target_pattern_types: string[];
  target_agent_nodes: string[];

  // Duration
  start_date: string;
  end_date: string | null;
  min_samples_per_variant: number;

  // Results
  winner_variant_id: string | null;
  final_confidence: number | null;

  created_at: string;
  updated_at: string;
}

export interface ExperimentMetrics {
  experiment_id: string;
  variant_id: string;
  total_impressions: number;
  total_feedback: number;
  positive_feedback: number;
  negative_feedback: number;
  conversion_rate: number;
  confidence_interval: [number, number];
  probability_best: number;
  expected_loss: number;
  updated_at: string;
}

export interface WeaknessReport {
  tenant_id: string;
  prompt_id: string;
  weakness_type: 'low_satisfaction' | 'declining_trend' | 'frequent_complaints';
  severity: WeaknessSeverity;
  current_satisfaction: number;
  target_satisfaction: number;
  sample_size: number;
  top_complaints: Array<{ reason: string; count: number }>;
  suggested_experiment: Partial<ExperimentConfig> | null;
  identified_at: string;
}

export interface OptimizationRecommendation {
  prompt_id: string;
  recommendation_type: 'create_experiment' | 'modify_prompt' | 'investigate' | 'no_action';
  priority: number;  // 1-10
  reason: string;
  suggested_changes: string[];
  estimated_impact: number;  // Percentage improvement expected
}
```

### Archivo: `src/features/ai/rlhf/prompts/base-prompts.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Base Prompts Registry
// Registro de prompts base del sistema
// =====================================================

import { PromptDefinition } from '../types/optimizer.types';

/**
 * System prompts used by TIS TIS AI agents
 * These are the baseline prompts that can be optimized
 */
export const BASE_PROMPTS: Record<string, PromptDefinition> = {
  // Classification prompts
  'classification.intent': {
    id: 'classification.intent',
    name: 'Intent Classification',
    category: 'classification',
    template: `Analiza el siguiente mensaje de un cliente y clasifica su intenciÃ³n principal.

Mensaje: {{message}}

Contexto del negocio: {{business_context}}

Clasifica en una de estas categorÃ­as:
- scheduling: Quiere agendar, modificar o cancelar una cita
- inquiry: Pregunta sobre servicios, precios o informaciÃ³n
- complaint: Queja o problema con el servicio
- feedback: Comentario positivo o reseÃ±a
- other: Otro tipo de mensaje

Responde SOLO con la categorÃ­a, sin explicaciÃ³n adicional.`,
    variables: ['message', 'business_context'],
    version: 1,
    created_at: '2026-01-01T00:00:00Z',
    updated_at: '2026-01-01T00:00:00Z',
  },

  // Response prompts
  'response.scheduling': {
    id: 'response.scheduling',
    name: 'Scheduling Response',
    category: 'response',
    template: `Eres un asistente de {{business_name}}, un {{business_type}}.

El cliente quiere agendar una cita. Responde de manera amable y profesional.

Mensaje del cliente: {{message}}
Servicios disponibles: {{services}}
Horarios disponibles: {{available_slots}}

GuÃ­a tu respuesta para:
1. Confirmar el servicio deseado
2. Ofrecer horarios disponibles
3. Solicitar informaciÃ³n necesaria (nombre, telÃ©fono si no lo tienes)

MantÃ©n un tono {{tone}} y respuestas concisas.`,
    variables: ['business_name', 'business_type', 'message', 'services', 'available_slots', 'tone'],
    version: 1,
    created_at: '2026-01-01T00:00:00Z',
    updated_at: '2026-01-01T00:00:00Z',
  },

  'response.inquiry': {
    id: 'response.inquiry',
    name: 'Inquiry Response',
    category: 'response',
    template: `Eres un asistente de {{business_name}}, un {{business_type}}.

El cliente tiene una pregunta. Responde de manera informativa y Ãºtil.

Pregunta del cliente: {{message}}
InformaciÃ³n del negocio: {{business_info}}
FAQ relevantes: {{faqs}}

Responde de forma {{tone}}, clara y directa. Si no tienes la informaciÃ³n, ofrece alternativas o sugiere contactar directamente.`,
    variables: ['business_name', 'business_type', 'message', 'business_info', 'faqs', 'tone'],
    version: 1,
    created_at: '2026-01-01T00:00:00Z',
    updated_at: '2026-01-01T00:00:00Z',
  },

  'response.complaint': {
    id: 'response.complaint',
    name: 'Complaint Response',
    category: 'response',
    template: `Eres un asistente de {{business_name}}, un {{business_type}}.

El cliente tiene una queja o problema. Es CRÃTICO manejar esto con empatÃ­a y profesionalismo.

Queja del cliente: {{message}}
Historial del cliente: {{customer_history}}
PolÃ­ticas relevantes: {{policies}}

IMPORTANTE:
1. Primero, muestra empatÃ­a genuina
2. Reconoce el problema sin excusas
3. Ofrece una soluciÃ³n concreta o escalamiento
4. MantÃ©n un tono {{tone}} pero nunca defensivo

Si el problema es grave, ofrece escalamiento a un humano.`,
    variables: ['business_name', 'business_type', 'message', 'customer_history', 'policies', 'tone'],
    version: 1,
    created_at: '2026-01-01T00:00:00Z',
    updated_at: '2026-01-01T00:00:00Z',
  },

  // Agent-specific prompts
  'agent.router': {
    id: 'agent.router',
    name: 'Router Agent',
    category: 'agent',
    template: `Eres el agente router de TIS TIS. Tu trabajo es analizar mensajes y dirigirlos al agente especializado correcto.

Mensaje a analizar: {{message}}
Contexto de conversaciÃ³n: {{conversation_context}}
Agentes disponibles: {{available_agents}}

Analiza el mensaje y decide:
1. QuÃ© agente debe manejarlo
2. QuÃ© informaciÃ³n adicional necesita ese agente
3. Si requiere informaciÃ³n del usuario antes de proceder

Responde en formato JSON:
{
  "target_agent": "agent_name",
  "context_to_pass": {},
  "needs_clarification": false,
  "clarification_question": null
}`,
    variables: ['message', 'conversation_context', 'available_agents'],
    version: 1,
    created_at: '2026-01-01T00:00:00Z',
    updated_at: '2026-01-01T00:00:00Z',
  },
};

/**
 * Get prompt by ID
 */
export function getBasePrompt(promptId: string): PromptDefinition | null {
  return BASE_PROMPTS[promptId] ?? null;
}

/**
 * Get all prompts by category
 */
export function getPromptsByCategory(category: PromptDefinition['category']): PromptDefinition[] {
  return Object.values(BASE_PROMPTS).filter(p => p.category === category);
}

/**
 * Render prompt with variables
 */
export function renderPrompt(promptId: string, variables: Record<string, string>): string {
  const prompt = getBasePrompt(promptId);
  if (!prompt) throw new Error(`Prompt not found: ${promptId}`);

  let rendered = prompt.template;
  for (const [key, value] of Object.entries(variables)) {
    rendered = rendered.replace(new RegExp(`{{${key}}}`, 'g'), value);
  }

  return rendered;
}
```

### Archivo: `src/features/ai/rlhf/experiments/variant-generator.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Prompt Variant Generator
// Genera variantes de prompts para A/B testing
// =====================================================

import { GoogleGenerativeAI } from '@google/generative-ai';
import { PromptDefinition, PromptVariant, VariantStrategy } from '../types/optimizer.types';
import { getBasePrompt } from '../prompts/base-prompts';

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_AI_API_KEY!);

interface VariantGenerationRequest {
  base_prompt_id: string;
  strategy: VariantStrategy;
  weakness_context: {
    low_satisfaction_areas: string[];
    common_complaints: string[];
    user_corrections: string[];
  };
  num_variants: number;
}

interface GeneratedVariant {
  variant_name: string;
  template: string;
  changes_description: string;
  hypothesis: string;
}

/**
 * Template-based variant modifications
 */
const TEMPLATE_MODIFICATIONS = {
  tone: {
    more_formal: {
      patterns: [
        { from: /Hola!/g, to: 'Buenos dÃ­as,' },
        { from: /Â¡Claro!/g, to: 'Por supuesto,' },
        { from: /Â¡Perfecto!/g, to: 'Excelente,' },
      ],
      description: 'Tono mÃ¡s formal y profesional',
    },
    more_friendly: {
      patterns: [
        { from: /Buenos dÃ­as,/g, to: 'Â¡Hola! ğŸ‘‹' },
        { from: /Por favor,/g, to: 'Si gustas,' },
        { from: /Gracias por contactarnos/g, to: 'Â¡Gracias por escribirnos!' },
      ],
      description: 'Tono mÃ¡s amigable y cercano',
    },
  },
  structure: {
    shorter: {
      instruction: 'MantÃ©n las respuestas cortas y directas, mÃ¡ximo 2-3 oraciones.',
      description: 'Respuestas mÃ¡s concisas',
    },
    with_bullets: {
      instruction: 'Usa viÃ±etas (â€¢) para listar opciones o pasos.',
      description: 'Formato con viÃ±etas para mejor lectura',
    },
  },
  empathy: {
    more_empathetic: {
      prefix: 'Entiendo tu situaciÃ³n. ',
      description: 'Mayor Ã©nfasis en empatÃ­a',
    },
    solution_focused: {
      prefix: 'Vamos a resolver esto. ',
      description: 'Enfoque directo en soluciÃ³n',
    },
  },
};

export class VariantGenerator {
  /**
   * Generate variants based on strategy
   */
  async generateVariants(request: VariantGenerationRequest): Promise<GeneratedVariant[]> {
    const basePrompt = getBasePrompt(request.base_prompt_id);
    if (!basePrompt) {
      throw new Error(`Base prompt not found: ${request.base_prompt_id}`);
    }

    switch (request.strategy) {
      case 'template':
        return this.generateTemplateVariants(basePrompt, request.num_variants);
      case 'ai_assisted':
        return this.generateAIVariants(basePrompt, request.weakness_context, request.num_variants);
      case 'feedback_driven':
        return this.generateFeedbackVariants(basePrompt, request.weakness_context, request.num_variants);
      default:
        throw new Error(`Unknown strategy: ${request.strategy}`);
    }
  }

  /**
   * Generate variants using predefined templates
   */
  private generateTemplateVariants(
    basePrompt: PromptDefinition,
    numVariants: number
  ): GeneratedVariant[] {
    const variants: GeneratedVariant[] = [];
    const modifications = Object.entries(TEMPLATE_MODIFICATIONS);

    for (let i = 0; i < Math.min(numVariants, modifications.length); i++) {
      const [category, options] = modifications[i];
      const optionKey = Object.keys(options)[0];
      const modification = options[optionKey as keyof typeof options];

      let modifiedTemplate = basePrompt.template;

      if ('patterns' in modification) {
        for (const pattern of modification.patterns) {
          modifiedTemplate = modifiedTemplate.replace(pattern.from, pattern.to);
        }
      } else if ('instruction' in modification) {
        modifiedTemplate = modifiedTemplate + '\n\n' + modification.instruction;
      } else if ('prefix' in modification) {
        // Add prefix to response instruction
        modifiedTemplate = modifiedTemplate.replace(
          /Responde/g,
          `${modification.prefix}Responde`
        );
      }

      variants.push({
        variant_name: `variant_${category}_${optionKey}`,
        template: modifiedTemplate,
        changes_description: modification.description,
        hypothesis: `Cambiar a ${modification.description} mejorarÃ¡ la satisfacciÃ³n`,
      });
    }

    return variants;
  }

  /**
   * Generate variants using AI assistance
   */
  private async generateAIVariants(
    basePrompt: PromptDefinition,
    weaknessContext: VariantGenerationRequest['weakness_context'],
    numVariants: number
  ): Promise<GeneratedVariant[]> {
    const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });

    const analysisPrompt = `Eres un experto en optimizaciÃ³n de prompts para asistentes de IA.

Analiza el siguiente prompt y sus problemas identificados:

PROMPT ACTUAL:
${basePrompt.template}

PROBLEMAS IDENTIFICADOS:
- Ãreas con baja satisfacciÃ³n: ${weaknessContext.low_satisfaction_areas.join(', ')}
- Quejas comunes: ${weaknessContext.common_complaints.join(', ')}
- Correcciones de usuarios: ${weaknessContext.user_corrections.slice(0, 3).join('; ')}

Genera ${numVariants} variantes mejoradas del prompt. Para cada variante:
1. MantÃ©n la estructura general y variables ({{variable}})
2. Mejora aspectos especÃ­ficos basÃ¡ndote en los problemas
3. SÃ© creativo pero mantÃ©n el propÃ³sito original

Responde en JSON:
{
  "variants": [
    {
      "variant_name": "variant_a",
      "template": "el prompt mejorado...",
      "changes_description": "quÃ© cambiÃ³",
      "hypothesis": "por quÃ© esto mejorarÃ¡"
    }
  ]
}`;

    try {
      const result = await model.generateContent(analysisPrompt);
      const text = result.response.text();

      // Extract JSON from response
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      if (!jsonMatch) throw new Error('No JSON found in response');

      const parsed = JSON.parse(jsonMatch[0]);
      return parsed.variants as GeneratedVariant[];
    } catch (error) {
      console.error('[VariantGenerator] AI generation failed:', error);
      // Fallback to template variants
      return this.generateTemplateVariants(basePrompt, numVariants);
    }
  }

  /**
   * Generate variants based on user feedback/corrections
   */
  private async generateFeedbackVariants(
    basePrompt: PromptDefinition,
    weaknessContext: VariantGenerationRequest['weakness_context'],
    numVariants: number
  ): Promise<GeneratedVariant[]> {
    const { user_corrections } = weaknessContext;

    if (user_corrections.length === 0) {
      // No corrections available, fallback to AI
      return this.generateAIVariants(basePrompt, weaknessContext, numVariants);
    }

    const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });

    const feedbackPrompt = `Analiza las siguientes correcciones que usuarios proporcionaron a respuestas del asistente:

CORRECCIONES DE USUARIOS:
${user_corrections.map((c, i) => `${i + 1}. "${c}"`).join('\n')}

PROMPT ACTUAL DEL ASISTENTE:
${basePrompt.template}

BasÃ¡ndote en lo que los usuarios esperaban vs lo que recibieron, genera ${numVariants} variantes del prompt que:
1. Incorporen los patrones de las correcciones
2. Eviten los errores que llevaron a las correcciones
3. Mantengan la estructura y variables ({{variable}})

Responde en JSON:
{
  "variants": [
    {
      "variant_name": "variant_feedback_1",
      "template": "el prompt mejorado...",
      "changes_description": "quÃ© cambiÃ³ basado en feedback",
      "hypothesis": "cÃ³mo esto evitarÃ¡ errores similares"
    }
  ]
}`;

    try {
      const result = await model.generateContent(feedbackPrompt);
      const text = result.response.text();

      const jsonMatch = text.match(/\{[\s\S]*\}/);
      if (!jsonMatch) throw new Error('No JSON found in response');

      const parsed = JSON.parse(jsonMatch[0]);
      return parsed.variants as GeneratedVariant[];
    } catch (error) {
      console.error('[VariantGenerator] Feedback generation failed:', error);
      return this.generateTemplateVariants(basePrompt, numVariants);
    }
  }
}

export const variantGenerator = new VariantGenerator();
```

### Archivo: `src/features/ai/rlhf/experiments/statistical-analyzer.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Statistical Analyzer for A/B Tests
// AnÃ¡lisis estadÃ­stico Bayesiano para experimentos
// =====================================================

import { ExperimentMetrics, PromptVariant } from '../types/optimizer.types';

interface BayesianResult {
  variant_id: string;
  samples: number;
  conversions: number;
  conversion_rate: number;
  probability_best: number;
  expected_loss: number;
  credible_interval: [number, number];
}

interface AnalysisResult {
  experiment_id: string;
  variants: BayesianResult[];
  winner: string | null;
  confidence: number;
  recommendation: 'continue' | 'stop_winner' | 'stop_no_winner';
  min_detectable_effect: number;
  power: number;
}

/**
 * Beta distribution sampling for Bayesian A/B testing
 */
function betaSample(alpha: number, beta: number): number {
  // Using approximation for beta distribution
  const x = gammaSample(alpha, 1);
  const y = gammaSample(beta, 1);
  return x / (x + y);
}

/**
 * Gamma distribution sampling (Marsaglia and Tsang's method)
 */
function gammaSample(shape: number, scale: number): number {
  if (shape < 1) {
    return gammaSample(1 + shape, scale) * Math.pow(Math.random(), 1 / shape);
  }

  const d = shape - 1 / 3;
  const c = 1 / Math.sqrt(9 * d);

  while (true) {
    let x: number, v: number;
    do {
      x = normalSample();
      v = 1 + c * x;
    } while (v <= 0);

    v = v * v * v;
    const u = Math.random();

    if (u < 1 - 0.0331 * (x * x) * (x * x)) {
      return d * v * scale;
    }

    if (Math.log(u) < 0.5 * x * x + d * (1 - v + Math.log(v))) {
      return d * v * scale;
    }
  }
}

/**
 * Standard normal sample (Box-Muller transform)
 */
function normalSample(): number {
  const u1 = Math.random();
  const u2 = Math.random();
  return Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
}

export class StatisticalAnalyzer {
  private numSimulations: number;
  private minSamplesForDecision: number;
  private confidenceThreshold: number;

  constructor(config: {
    numSimulations?: number;
    minSamplesForDecision?: number;
    confidenceThreshold?: number;
  } = {}) {
    this.numSimulations = config.numSimulations ?? 10000;
    this.minSamplesForDecision = config.minSamplesForDecision ?? 100;
    this.confidenceThreshold = config.confidenceThreshold ?? 0.95;
  }

  /**
   * Analyze experiment results using Bayesian methods
   */
  analyzeExperiment(
    experimentId: string,
    variantMetrics: Array<{
      variant_id: string;
      impressions: number;
      positive_feedback: number;
    }>
  ): AnalysisResult {
    const results: BayesianResult[] = [];
    const winCounts: Record<string, number> = {};

    // Initialize win counts
    for (const vm of variantMetrics) {
      winCounts[vm.variant_id] = 0;
    }

    // Run Monte Carlo simulations
    for (let sim = 0; sim < this.numSimulations; sim++) {
      const samples: Array<{ id: string; value: number }> = [];

      for (const vm of variantMetrics) {
        // Beta distribution with Jeffreys prior (0.5, 0.5)
        const alpha = 0.5 + vm.positive_feedback;
        const beta = 0.5 + (vm.impressions - vm.positive_feedback);
        const sample = betaSample(alpha, beta);
        samples.push({ id: vm.variant_id, value: sample });
      }

      // Find winner of this simulation
      const winner = samples.reduce((best, curr) =>
        curr.value > best.value ? curr : best
      );
      winCounts[winner.id]++;
    }

    // Calculate metrics for each variant
    for (const vm of variantMetrics) {
      const alpha = 0.5 + vm.positive_feedback;
      const beta = 0.5 + (vm.impressions - vm.positive_feedback);

      const conversionRate = vm.impressions > 0
        ? vm.positive_feedback / vm.impressions
        : 0;

      const probabilityBest = winCounts[vm.variant_id] / this.numSimulations;

      // Calculate expected loss (opportunity cost of choosing this variant)
      const expectedLoss = this.calculateExpectedLoss(
        vm.variant_id,
        variantMetrics
      );

      // Credible interval (95%)
      const credibleInterval = this.calculateCredibleInterval(alpha, beta);

      results.push({
        variant_id: vm.variant_id,
        samples: vm.impressions,
        conversions: vm.positive_feedback,
        conversion_rate: conversionRate,
        probability_best: probabilityBest,
        expected_loss: expectedLoss,
        credible_interval: credibleInterval,
      });
    }

    // Determine winner and recommendation
    const { winner, confidence, recommendation } = this.determineWinner(
      results,
      variantMetrics
    );

    // Calculate statistical power
    const power = this.calculatePower(variantMetrics);

    return {
      experiment_id: experimentId,
      variants: results,
      winner,
      confidence,
      recommendation,
      min_detectable_effect: 0.05, // 5% minimum detectable effect
      power,
    };
  }

  /**
   * Calculate expected loss for a variant
   */
  private calculateExpectedLoss(
    variantId: string,
    metrics: Array<{ variant_id: string; impressions: number; positive_feedback: number }>
  ): number {
    let totalLoss = 0;

    for (let sim = 0; sim < 1000; sim++) {
      const samples: Array<{ id: string; value: number }> = [];

      for (const vm of metrics) {
        const alpha = 0.5 + vm.positive_feedback;
        const beta = 0.5 + (vm.impressions - vm.positive_feedback);
        samples.push({ id: vm.variant_id, value: betaSample(alpha, beta) });
      }

      const maxValue = Math.max(...samples.map(s => s.value));
      const thisValue = samples.find(s => s.id === variantId)?.value ?? 0;
      totalLoss += maxValue - thisValue;
    }

    return totalLoss / 1000;
  }

  /**
   * Calculate 95% credible interval
   */
  private calculateCredibleInterval(alpha: number, beta: number): [number, number] {
    const samples: number[] = [];

    for (let i = 0; i < 10000; i++) {
      samples.push(betaSample(alpha, beta));
    }

    samples.sort((a, b) => a - b);

    return [
      samples[Math.floor(0.025 * samples.length)],
      samples[Math.floor(0.975 * samples.length)],
    ];
  }

  /**
   * Determine if there's a clear winner
   */
  private determineWinner(
    results: BayesianResult[],
    metrics: Array<{ impressions: number }>
  ): { winner: string | null; confidence: number; recommendation: 'continue' | 'stop_winner' | 'stop_no_winner' } {
    const totalSamples = metrics.reduce((sum, m) => sum + m.impressions, 0);

    // Not enough samples
    if (totalSamples < this.minSamplesForDecision * results.length) {
      return {
        winner: null,
        confidence: 0,
        recommendation: 'continue',
      };
    }

    // Find best variant
    const bestVariant = results.reduce((best, curr) =>
      curr.probability_best > best.probability_best ? curr : best
    );

    // Check if confidence threshold is met
    if (bestVariant.probability_best >= this.confidenceThreshold) {
      return {
        winner: bestVariant.variant_id,
        confidence: bestVariant.probability_best,
        recommendation: 'stop_winner',
      };
    }

    // Check if we should stop due to no practical difference
    const rates = results.map(r => r.conversion_rate);
    const maxRate = Math.max(...rates);
    const minRate = Math.min(...rates);

    if (maxRate - minRate < 0.02 && totalSamples > this.minSamplesForDecision * 3) {
      // Less than 2% difference with sufficient samples
      return {
        winner: null,
        confidence: 1 - (maxRate - minRate) / maxRate,
        recommendation: 'stop_no_winner',
      };
    }

    return {
      winner: null,
      confidence: bestVariant.probability_best,
      recommendation: 'continue',
    };
  }

  /**
   * Calculate statistical power
   */
  private calculatePower(
    metrics: Array<{ impressions: number; positive_feedback: number }>
  ): number {
    // Simplified power calculation
    const totalSamples = metrics.reduce((sum, m) => sum + m.impressions, 0);
    const avgRate = metrics.reduce((sum, m) => sum + m.positive_feedback, 0) / totalSamples;

    // Power increases with sample size and decreases with variance
    const variance = avgRate * (1 - avgRate);
    const standardError = Math.sqrt(variance / totalSamples);

    // Effect size we want to detect (5%)
    const effectSize = 0.05;
    const zScore = effectSize / standardError;

    // Approximate power using normal CDF
    const power = 1 - normalCDF(-zScore + 1.96); // One-sided test at 95%

    return Math.min(1, Math.max(0, power));
  }
}

/**
 * Standard normal CDF approximation
 */
function normalCDF(x: number): number {
  const a1 = 0.254829592;
  const a2 = -0.284496736;
  const a3 = 1.421413741;
  const a4 = -1.453152027;
  const a5 = 1.061405429;
  const p = 0.3275911;

  const sign = x < 0 ? -1 : 1;
  x = Math.abs(x) / Math.sqrt(2);

  const t = 1.0 / (1.0 + p * x);
  const y = 1.0 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * Math.exp(-x * x);

  return 0.5 * (1.0 + sign * y);
}

export const statisticalAnalyzer = new StatisticalAnalyzer();
```

### Archivo: `src/features/ai/rlhf/services/prompt-optimizer.service.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Prompt Optimizer Service
// Servicio principal de optimizaciÃ³n de prompts
// =====================================================

import { createClient, SupabaseClient } from '@supabase/supabase-js';
import {
  ExperimentConfig,
  ExperimentStatus,
  OptimizationRecommendation,
  PromptVariant,
  WeaknessReport,
} from '../types/optimizer.types';
import { AggregatedMetrics } from '../types/aggregation.types';
import { feedbackAggregator } from './feedback-aggregator.service';
import { variantGenerator } from '../experiments/variant-generator';
import { statisticalAnalyzer } from '../experiments/statistical-analyzer';
import { getBasePrompt, BASE_PROMPTS } from '../prompts/base-prompts';

interface OptimizerConfig {
  satisfactionThreshold: number;
  trendDeclineThreshold: number;
  minFeedbackForAnalysis: number;
  maxActiveExperiments: number;
}

const DEFAULT_CONFIG: OptimizerConfig = {
  satisfactionThreshold: 0.7,
  trendDeclineThreshold: -0.1,
  minFeedbackForAnalysis: 20,
  maxActiveExperiments: 3,
};

export class PromptOptimizerService {
  private supabase: SupabaseClient;
  private config: OptimizerConfig;

  constructor(config: Partial<OptimizerConfig> = {}) {
    this.supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!
    );
    this.config = { ...DEFAULT_CONFIG, ...config };
  }

  /**
   * Analyze tenant prompts and identify weaknesses
   */
  async analyzeWeaknesses(tenantId: string): Promise<WeaknessReport[]> {
    const reports: WeaknessReport[] = [];

    // Get aggregated metrics
    const metrics = await feedbackAggregator.getAggregatedMetrics(tenantId, {
      period: '7d',
    });

    // Group by prompt category (response_type maps to prompt category)
    const byResponseType = metrics.filter(m => m.dimension_type === 'response_type');

    for (const metric of byResponseType) {
      const promptId = this.mapResponseTypeToPrompt(metric.dimension_value);
      if (!promptId) continue;

      // Check for low satisfaction
      if (metric.satisfaction_rate < this.config.satisfactionThreshold) {
        reports.push({
          tenant_id: tenantId,
          prompt_id: promptId,
          weakness_type: 'low_satisfaction',
          severity: this.calculateSeverity(metric.satisfaction_rate),
          current_satisfaction: metric.satisfaction_rate,
          target_satisfaction: this.config.satisfactionThreshold,
          sample_size: metric.total_feedback,
          top_complaints: metric.top_negative_reasons,
          suggested_experiment: await this.suggestExperiment(tenantId, promptId, metric),
          identified_at: new Date().toISOString(),
        });
      }

      // Check for declining trend
      if (
        metric.trend_direction === 'declining' &&
        metric.trend_magnitude < this.config.trendDeclineThreshold
      ) {
        reports.push({
          tenant_id: tenantId,
          prompt_id: promptId,
          weakness_type: 'declining_trend',
          severity: 'high',
          current_satisfaction: metric.satisfaction_rate,
          target_satisfaction: metric.satisfaction_rate - metric.trend_magnitude,
          sample_size: metric.total_feedback,
          top_complaints: metric.top_negative_reasons,
          suggested_experiment: await this.suggestExperiment(tenantId, promptId, metric),
          identified_at: new Date().toISOString(),
        });
      }
    }

    return reports;
  }

  /**
   * Create an optimization experiment
   */
  async createExperiment(
    tenantId: string,
    config: {
      promptId: string;
      name: string;
      description: string;
      strategy: 'template' | 'ai_assisted' | 'feedback_driven';
      numVariants: number;
      trafficPercentage: number;
      minSamplesPerVariant: number;
    }
  ): Promise<ExperimentConfig> {
    // Check active experiments limit
    const { count: activeCount } = await this.supabase
      .from('ai_prompt_experiments')
      .select('*', { count: 'exact', head: true })
      .eq('tenant_id', tenantId)
      .eq('status', 'active');

    if ((activeCount ?? 0) >= this.config.maxActiveExperiments) {
      throw new Error(
        `Maximum active experiments (${this.config.maxActiveExperiments}) reached`
      );
    }

    // Get weakness context for variant generation
    const weaknessContext = await this.getWeaknessContext(tenantId, config.promptId);

    // Generate variants
    const generatedVariants = await variantGenerator.generateVariants({
      base_prompt_id: config.promptId,
      strategy: config.strategy,
      weakness_context: weaknessContext,
      num_variants: config.numVariants,
    });

    // Build experiment config
    const basePrompt = getBasePrompt(config.promptId);
    if (!basePrompt) throw new Error(`Prompt not found: ${config.promptId}`);

    const experimentId = `exp_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

    // Calculate traffic split
    const variantTraffic = config.trafficPercentage / (generatedVariants.length + 1);
    const controlTraffic = 100 - config.trafficPercentage;

    const variants: PromptVariant[] = [
      // Control variant
      {
        variant_id: `${experimentId}_control`,
        experiment_id: experimentId,
        base_prompt_id: config.promptId,
        variant_name: 'control',
        template: basePrompt.template,
        strategy: config.strategy,
        changes_description: 'Original prompt (control)',
        hypothesis: 'Baseline performance',
        traffic_percentage: controlTraffic,
        is_control: true,
      },
      // Generated variants
      ...generatedVariants.map((gv, index) => ({
        variant_id: `${experimentId}_${gv.variant_name}`,
        experiment_id: experimentId,
        base_prompt_id: config.promptId,
        variant_name: gv.variant_name,
        template: gv.template,
        strategy: config.strategy,
        changes_description: gv.changes_description,
        hypothesis: gv.hypothesis,
        traffic_percentage: variantTraffic,
        is_control: false,
      })),
    ];

    const experiment: ExperimentConfig = {
      id: experimentId,
      tenant_id: tenantId,
      name: config.name,
      description: config.description,
      prompt_category: basePrompt.category,
      status: 'draft',
      variants,
      target_pattern_types: [],
      target_agent_nodes: [],
      start_date: new Date().toISOString(),
      end_date: null,
      min_samples_per_variant: config.minSamplesPerVariant,
      winner_variant_id: null,
      final_confidence: null,
      created_at: new Date().toISOString(),
      updated_at: new Date().toISOString(),
    };

    // Save to database
    const { error } = await this.supabase
      .from('ai_prompt_experiments')
      .insert(experiment);

    if (error) throw error;

    return experiment;
  }

  /**
   * Start an experiment (move from draft to active)
   */
  async startExperiment(experimentId: string): Promise<void> {
    const { error } = await this.supabase
      .from('ai_prompt_experiments')
      .update({
        status: 'active',
        start_date: new Date().toISOString(),
        updated_at: new Date().toISOString(),
      })
      .eq('id', experimentId)
      .eq('status', 'draft');

    if (error) throw error;
  }

  /**
   * Analyze experiment and determine winner
   */
  async analyzeExperiment(experimentId: string): Promise<{
    analysis: ReturnType<typeof statisticalAnalyzer.analyzeExperiment>;
    recommendation: string;
  }> {
    // Get experiment
    const { data: experiment, error } = await this.supabase
      .from('ai_prompt_experiments')
      .select('*')
      .eq('id', experimentId)
      .single();

    if (error || !experiment) throw new Error('Experiment not found');

    // Get feedback metrics per variant
    const variantMetrics = await this.getVariantMetrics(experimentId);

    // Run statistical analysis
    const analysis = statisticalAnalyzer.analyzeExperiment(
      experimentId,
      variantMetrics
    );

    // Generate recommendation
    let recommendation: string;
    switch (analysis.recommendation) {
      case 'stop_winner':
        recommendation = `Experimento concluido. Ganador: ${analysis.winner} con ${(analysis.confidence * 100).toFixed(1)}% de confianza. Se recomienda promover a producciÃ³n.`;
        break;
      case 'stop_no_winner':
        recommendation = `No hay diferencia significativa entre variantes. Se recomienda terminar el experimento y mantener el prompt actual.`;
        break;
      case 'continue':
        recommendation = `Continuar el experimento. Se necesitan mÃ¡s datos para determinar un ganador claro.`;
        break;
    }

    return { analysis, recommendation };
  }

  /**
   * Promote winning variant to production
   */
  async promoteWinner(experimentId: string): Promise<void> {
    const { analysis } = await this.analyzeExperiment(experimentId);

    if (!analysis.winner) {
      throw new Error('No winner determined yet');
    }

    // Get winning variant
    const { data: experiment } = await this.supabase
      .from('ai_prompt_experiments')
      .select('*')
      .eq('id', experimentId)
      .single();

    if (!experiment) throw new Error('Experiment not found');

    const winnerVariant = experiment.variants.find(
      (v: PromptVariant) => v.variant_id === analysis.winner
    );

    if (!winnerVariant) throw new Error('Winner variant not found');

    // Update experiment status
    await this.supabase
      .from('ai_prompt_experiments')
      .update({
        status: 'completed',
        winner_variant_id: analysis.winner,
        final_confidence: analysis.confidence,
        end_date: new Date().toISOString(),
        updated_at: new Date().toISOString(),
      })
      .eq('id', experimentId);

    // TODO: Update base prompt registry with winner
    // This would require a separate prompt versioning system
    console.log(`[Optimizer] Winner promoted: ${winnerVariant.variant_name}`);
  }

  /**
   * Get the active prompt variant for a given context
   */
  async getActivePrompt(
    tenantId: string,
    promptId: string,
    context: Record<string, unknown> = {}
  ): Promise<{ template: string; variant_id: string | null; experiment_id: string | null }> {
    // Check for active experiment
    const { data: experiments } = await this.supabase
      .from('ai_prompt_experiments')
      .select('*')
      .eq('tenant_id', tenantId)
      .eq('status', 'active')
      .contains('variants', [{ base_prompt_id: promptId }]);

    if (experiments && experiments.length > 0) {
      const experiment = experiments[0];
      const selectedVariant = this.selectVariant(experiment.variants);

      return {
        template: selectedVariant.template,
        variant_id: selectedVariant.variant_id,
        experiment_id: experiment.id,
      };
    }

    // No active experiment, return base prompt
    const basePrompt = getBasePrompt(promptId);
    if (!basePrompt) throw new Error(`Prompt not found: ${promptId}`);

    return {
      template: basePrompt.template,
      variant_id: null,
      experiment_id: null,
    };
  }

  /**
   * Generate optimization recommendations
   */
  async getRecommendations(tenantId: string): Promise<OptimizationRecommendation[]> {
    const weaknesses = await this.analyzeWeaknesses(tenantId);
    const recommendations: OptimizationRecommendation[] = [];

    for (const weakness of weaknesses) {
      const priority = this.calculatePriority(weakness);

      recommendations.push({
        prompt_id: weakness.prompt_id,
        recommendation_type: weakness.severity === 'critical' ? 'create_experiment' : 'investigate',
        priority,
        reason: this.formatWeaknessReason(weakness),
        suggested_changes: weakness.top_complaints.map(c => `Abordar queja: "${c.reason}"`),
        estimated_impact: (weakness.target_satisfaction - weakness.current_satisfaction) * 100,
      });
    }

    return recommendations.sort((a, b) => b.priority - a.priority);
  }

  // ==================== Private Methods ====================

  private mapResponseTypeToPrompt(responseType: string): string | null {
    const mapping: Record<string, string> = {
      scheduling: 'response.scheduling',
      inquiry: 'response.inquiry',
      complaint: 'response.complaint',
      classification: 'classification.intent',
    };
    return mapping[responseType] ?? null;
  }

  private calculateSeverity(satisfaction: number): 'critical' | 'high' | 'medium' | 'low' {
    if (satisfaction < 0.4) return 'critical';
    if (satisfaction < 0.5) return 'high';
    if (satisfaction < 0.6) return 'medium';
    return 'low';
  }

  private async suggestExperiment(
    tenantId: string,
    promptId: string,
    metric: AggregatedMetrics
  ): Promise<Partial<ExperimentConfig>> {
    return {
      tenant_id: tenantId,
      name: `Optimize ${promptId}`,
      description: `Experiment to improve ${metric.dimension_value} responses (current satisfaction: ${(metric.satisfaction_rate * 100).toFixed(1)}%)`,
      prompt_category: getBasePrompt(promptId)?.category ?? 'response',
      target_pattern_types: [metric.dimension_value],
      min_samples_per_variant: Math.max(50, metric.total_feedback * 2),
    };
  }

  private async getWeaknessContext(
    tenantId: string,
    promptId: string
  ): Promise<{
    low_satisfaction_areas: string[];
    common_complaints: string[];
    user_corrections: string[];
  }> {
    // Get aggregated data for this prompt
    const metrics = await feedbackAggregator.getAggregatedMetrics(tenantId, { period: '30d' });

    const relevantMetrics = metrics.filter(
      m => this.mapResponseTypeToPrompt(m.dimension_value) === promptId
    );

    // Get user corrections from feedback
    const { data: feedback } = await this.supabase
      .from('ai_rlhf_feedback')
      .select('expected_response, feedback_reason')
      .eq('tenant_id', tenantId)
      .eq('feedback_type', 'negative')
      .not('expected_response', 'is', null)
      .limit(20);

    return {
      low_satisfaction_areas: relevantMetrics
        .filter(m => m.satisfaction_rate < 0.7)
        .map(m => m.dimension_value),
      common_complaints: relevantMetrics
        .flatMap(m => m.top_negative_reasons)
        .slice(0, 10)
        .map(r => r.reason),
      user_corrections: feedback?.map(f => f.expected_response).filter(Boolean) ?? [],
    };
  }

  private async getVariantMetrics(experimentId: string): Promise<
    Array<{
      variant_id: string;
      impressions: number;
      positive_feedback: number;
    }>
  > {
    // Aggregate feedback by variant
    const { data: feedback } = await this.supabase
      .from('ai_rlhf_feedback')
      .select('metadata, feedback_type')
      .eq('metadata->>experiment_id', experimentId);

    const variantStats: Record<string, { impressions: number; positive: number }> = {};

    for (const f of feedback ?? []) {
      const variantId = f.metadata?.variant_id;
      if (!variantId) continue;

      if (!variantStats[variantId]) {
        variantStats[variantId] = { impressions: 0, positive: 0 };
      }

      variantStats[variantId].impressions++;
      if (f.feedback_type === 'positive') {
        variantStats[variantId].positive++;
      }
    }

    return Object.entries(variantStats).map(([variant_id, stats]) => ({
      variant_id,
      impressions: stats.impressions,
      positive_feedback: stats.positive,
    }));
  }

  private selectVariant(variants: PromptVariant[]): PromptVariant {
    // Weighted random selection based on traffic percentage
    const random = Math.random() * 100;
    let cumulative = 0;

    for (const variant of variants) {
      cumulative += variant.traffic_percentage;
      if (random <= cumulative) {
        return variant;
      }
    }

    // Fallback to control
    return variants.find(v => v.is_control) ?? variants[0];
  }

  private calculatePriority(weakness: WeaknessReport): number {
    let priority = 5; // Base priority

    // Severity adjustment
    switch (weakness.severity) {
      case 'critical': priority += 4; break;
      case 'high': priority += 3; break;
      case 'medium': priority += 2; break;
      case 'low': priority += 1; break;
    }

    // Sample size bonus (more data = more confidence)
    if (weakness.sample_size > 100) priority += 1;

    return Math.min(10, priority);
  }

  private formatWeaknessReason(weakness: WeaknessReport): string {
    switch (weakness.weakness_type) {
      case 'low_satisfaction':
        return `SatisfacciÃ³n actual (${(weakness.current_satisfaction * 100).toFixed(1)}%) estÃ¡ por debajo del objetivo (${(weakness.target_satisfaction * 100).toFixed(1)}%)`;
      case 'declining_trend':
        return `Tendencia decreciente detectada. La satisfacciÃ³n estÃ¡ bajando.`;
      case 'frequent_complaints':
        return `Alto volumen de quejas: ${weakness.top_complaints[0]?.reason ?? 'Sin detalle'}`;
      default:
        return 'Ãrea de mejora identificada';
    }
  }
}

export const promptOptimizer = new PromptOptimizerService();
```

---

## ğŸ”— Integration con LangGraph

### Modificar: `src/features/ai/graph/tistis-graph.ts`

```typescript
// Agregar al inicio del archivo
import { promptOptimizer } from '../rlhf/services/prompt-optimizer.service';

// Modificar la funciÃ³n que genera respuestas para usar el optimizer
async function getOptimizedPrompt(
  tenantId: string,
  promptId: string,
  defaultTemplate: string
): Promise<{ template: string; tracking: { variant_id: string | null; experiment_id: string | null } }> {
  try {
    const result = await promptOptimizer.getActivePrompt(tenantId, promptId);
    return {
      template: result.template,
      tracking: {
        variant_id: result.variant_id,
        experiment_id: result.experiment_id,
      },
    };
  } catch (error) {
    console.warn('[TistisGraph] Failed to get optimized prompt, using default:', error);
    return {
      template: defaultTemplate,
      tracking: { variant_id: null, experiment_id: null },
    };
  }
}

// Ejemplo de uso en un nodo del graph
async function responseNode(state: GraphState): Promise<GraphState> {
  const { tenantId, intent, message } = state;

  // Get optimized prompt
  const promptId = `response.${intent}`;
  const { template, tracking } = await getOptimizedPrompt(
    tenantId,
    promptId,
    DEFAULT_RESPONSE_TEMPLATE
  );

  // Generate response using optimized template
  const response = await generateResponse(template, state.context);

  // Store tracking info for feedback attribution
  return {
    ...state,
    response,
    metadata: {
      ...state.metadata,
      prompt_variant_id: tracking.variant_id,
      experiment_id: tracking.experiment_id,
    },
  };
}
```

---

## âœ… Checklist de ImplementaciÃ³n

### Pre-requisitos
- [ ] Aggregator funcionando (1.4)
- [ ] Tabla `ai_prompt_experiments` creada (1.1)
- [ ] Google AI API key configurada

### ImplementaciÃ³n

```
â–¡ Paso 1: Crear tipos
â”œâ”€â”€ [ ] Crear archivo optimizer.types.ts
â”œâ”€â”€ [ ] Definir interfaces de experimentos
â””â”€â”€ [ ] Definir tipos de variantes

â–¡ Paso 2: Crear registro de prompts
â”œâ”€â”€ [ ] Crear base-prompts.ts
â”œâ”€â”€ [ ] Definir prompts base del sistema
â”œâ”€â”€ [ ] Implementar renderPrompt helper
â””â”€â”€ [ ] Unit tests

â–¡ Paso 3: Implementar generador de variantes
â”œâ”€â”€ [ ] Crear variant-generator.ts
â”œâ”€â”€ [ ] Implementar estrategia template
â”œâ”€â”€ [ ] Implementar estrategia AI-assisted
â”œâ”€â”€ [ ] Implementar estrategia feedback-driven
â””â”€â”€ [ ] Integration tests

â–¡ Paso 4: Implementar analizador estadÃ­stico
â”œâ”€â”€ [ ] Crear statistical-analyzer.ts
â”œâ”€â”€ [ ] Implementar Bayesian A/B testing
â”œâ”€â”€ [ ] Implementar cÃ¡lculo de expected loss
â”œâ”€â”€ [ ] Implementar determinaciÃ³n de ganador
â””â”€â”€ [ ] Unit tests con datos simulados

â–¡ Paso 5: Implementar servicio optimizer
â”œâ”€â”€ [ ] Crear prompt-optimizer.service.ts
â”œâ”€â”€ [ ] Implementar analyzeWeaknesses
â”œâ”€â”€ [ ] Implementar createExperiment
â”œâ”€â”€ [ ] Implementar analyzeExperiment
â”œâ”€â”€ [ ] Implementar promoteWinner
â”œâ”€â”€ [ ] Implementar getActivePrompt
â””â”€â”€ [ ] Integration tests

â–¡ Paso 6: Integrar con LangGraph
â”œâ”€â”€ [ ] Modificar tistis-graph.ts
â”œâ”€â”€ [ ] Agregar tracking de variantes
â”œâ”€â”€ [ ] Probar flujo completo
â””â”€â”€ [ ] E2E tests
```

### ValidaciÃ³n

```bash
# Test creaciÃ³n de experimento
curl -X POST "http://localhost:3000/api/rlhf/experiments" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "promptId": "response.scheduling",
    "name": "Test Experiment",
    "strategy": "ai_assisted",
    "numVariants": 2
  }'

# Test anÃ¡lisis de experimento
curl -X GET "http://localhost:3000/api/rlhf/experiments/{id}/analysis" \
  -H "Authorization: Bearer $TOKEN"

# Verificar selecciÃ³n de variantes
SELECT variant_id, COUNT(*) as count
FROM ai_rlhf_feedback
WHERE metadata->>'experiment_id' = 'exp_xxx'
GROUP BY variant_id;
```

---

## ğŸ“ Notas de ImplementaciÃ³n

### Consideraciones de Performance

1. **Caching de prompts**: Cachear prompts activos por 5 minutos
2. **Lazy loading**: Solo cargar experimentos activos
3. **Batch processing**: Procesar anÃ¡lisis estadÃ­stico en batches

### Limitaciones Conocidas

1. **MÃ­nimo de datos**: Requiere ~100 feedbacks por variante para resultados confiables
2. **Tiempo de experimento**: MÃ­nimo 2 semanas para detectar efectos pequeÃ±os
3. **Un experimento por prompt**: Evitar conflictos de trÃ¡fico

### Mejoras Futuras

1. **Multi-armed bandit**: OptimizaciÃ³n dinÃ¡mica de trÃ¡fico
2. **Contextual bandits**: Variantes por segmento de usuario
3. **Auto-ML**: GeneraciÃ³n automÃ¡tica de experimentos

---

**Siguiente documento:** [1.6-TESTING.md](./1.6-TESTING.md)
