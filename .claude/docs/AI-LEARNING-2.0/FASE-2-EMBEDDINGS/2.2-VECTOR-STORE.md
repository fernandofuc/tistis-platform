# ğŸ—„ï¸ FASE 2.2: Vector Store (pgvector)

## Almacenamiento de Vectores con PostgreSQL

**Documento:** 2.2-VECTOR-STORE.md
**Fase:** 2 - Embeddings SemÃ¡nticos
**DuraciÃ³n estimada:** 1-1.5 semanas
**Dependencias:** 2.1 (Embedding Service), Supabase con pgvector

---

## ğŸ“‹ Ãndice

1. [Objetivo](#objetivo)
2. [pgvector Overview](#pgvector-overview)
3. [Schema Design](#schema-design)
4. [Indexing Strategy](#indexing-strategy)
5. [ImplementaciÃ³n](#implementaciÃ³n)
6. [Queries Optimizadas](#queries-optimizadas)
7. [Checklist de ImplementaciÃ³n](#checklist-de-implementaciÃ³n)

---

## ğŸ¯ Objetivo

Implementar un vector store eficiente usando pgvector en Supabase para almacenar y buscar embeddings semÃ¡nticos de patrones, mensajes y FAQs.

### Arquitectura del Vector Store

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VECTOR STORE ARCHITECTURE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     SUPABASE                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚   â”‚
â”‚  â”‚  â”‚                  PostgreSQL                         â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚              pgvector extension               â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                                               â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ ai_pattern_ â”‚    â”‚ ai_document_        â”‚  â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ embeddings  â”‚    â”‚ embeddings          â”‚  â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚             â”‚    â”‚                     â”‚  â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ tenant_id   â”‚    â”‚ tenant_id           â”‚  â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ pattern_typeâ”‚    â”‚ document_type       â”‚  â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ embedding   â”‚    â”‚ embedding           â”‚  â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ [1536]      â”‚    â”‚ [1536]              â”‚  â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                                               â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚           HNSW Index                    â”‚ â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚   (Hierarchical Navigable Small World)  â”‚ â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚   - Fast approximate nearest neighbor   â”‚ â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â”‚   - Sub-linear query time               â”‚ â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â”‚                                               â”‚ â”‚â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š pgvector Overview

### Â¿QuÃ© es pgvector?

pgvector es una extensiÃ³n de PostgreSQL que agrega soporte para:
- **Tipos de datos vectoriales**: `VECTOR(n)` para almacenar arrays de floats
- **Operadores de distancia**: Coseno, Euclidiana, Inner Product
- **Ãndices especializados**: IVFFlat, HNSW para bÃºsqueda aproximada

### Operadores de Distancia

| Operador | Nombre | DescripciÃ³n | Rango |
|----------|--------|-------------|-------|
| `<->` | L2 (Euclidean) | Distancia euclidiana | 0 â†’ âˆ |
| `<#>` | Inner Product | Producto interno negativo | -âˆ â†’ âˆ |
| `<=>` | Cosine | Distancia coseno | 0 â†’ 2 |

### Tipos de Ãndices

| Ãndice | Velocidad | PrecisiÃ³n | Memoria | Uso |
|--------|-----------|-----------|---------|-----|
| None (exact) | Lento | 100% | Baja | < 10K vectores |
| IVFFlat | RÃ¡pido | ~95% | Media | 10K-1M vectores |
| HNSW | Muy rÃ¡pido | ~99% | Alta | > 100K vectores |

**RecomendaciÃ³n para TIS TIS**: HNSW para mejor balance velocidad/precisiÃ³n

---

## ğŸ—ƒï¸ Schema Design

### Migration SQL: `210_VECTOR_STORE.sql`

```sql
-- =====================================================
-- TIS TIS PLATFORM - Vector Store Schema
-- Tablas para almacenamiento de embeddings con pgvector
-- =====================================================

-- Enable pgvector extension (if not already enabled)
CREATE EXTENSION IF NOT EXISTS vector;

-- =====================================================
-- TABLE: ai_pattern_embeddings
-- Embeddings para patrones de mensajes
-- =====================================================

CREATE TABLE IF NOT EXISTS ai_pattern_embeddings (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id UUID NOT NULL REFERENCES tenants(id) ON DELETE CASCADE,

  -- Pattern identification
  pattern_id UUID REFERENCES ai_message_patterns(id) ON DELETE CASCADE,
  pattern_type TEXT NOT NULL,
  pattern_text TEXT NOT NULL,

  -- Embedding vector (1536 dimensions for text-embedding-3-small)
  embedding VECTOR(1536) NOT NULL,

  -- Metadata
  model TEXT NOT NULL DEFAULT 'text-embedding-3-small',
  token_count INTEGER,

  -- Timestamps
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),

  -- Constraints
  CONSTRAINT unique_pattern_embedding UNIQUE (tenant_id, pattern_id)
);

-- =====================================================
-- TABLE: ai_document_embeddings
-- Embeddings para documentos (FAQs, polÃ­ticas, etc.)
-- =====================================================

CREATE TABLE IF NOT EXISTS ai_document_embeddings (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id UUID NOT NULL REFERENCES tenants(id) ON DELETE CASCADE,

  -- Document identification
  document_type TEXT NOT NULL, -- 'faq', 'policy', 'service', 'menu_item'
  document_id UUID, -- Reference to source document
  document_title TEXT NOT NULL,
  document_content TEXT NOT NULL,

  -- Chunking (for large documents)
  chunk_index INTEGER DEFAULT 0,
  chunk_start INTEGER DEFAULT 0,
  chunk_end INTEGER,
  total_chunks INTEGER DEFAULT 1,

  -- Embedding
  embedding VECTOR(1536) NOT NULL,
  model TEXT NOT NULL DEFAULT 'text-embedding-3-small',
  token_count INTEGER,

  -- Metadata for filtering
  metadata JSONB DEFAULT '{}',
  tags TEXT[] DEFAULT '{}',

  -- Status
  is_active BOOLEAN DEFAULT TRUE,

  -- Timestamps
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- =====================================================
-- TABLE: ai_message_embeddings
-- Embeddings histÃ³ricos de mensajes (para anÃ¡lisis)
-- =====================================================

CREATE TABLE IF NOT EXISTS ai_message_embeddings (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id UUID NOT NULL REFERENCES tenants(id) ON DELETE CASCADE,

  -- Message reference
  message_id UUID NOT NULL,
  conversation_id UUID,

  -- Message content
  message_text TEXT NOT NULL,
  message_role TEXT NOT NULL, -- 'user', 'assistant'

  -- Embedding
  embedding VECTOR(1536) NOT NULL,
  model TEXT NOT NULL DEFAULT 'text-embedding-3-small',

  -- Classification result (filled after classification)
  classified_intent TEXT,
  classification_confidence FLOAT,

  -- Timestamps
  message_timestamp TIMESTAMPTZ,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- =====================================================
-- INDEXES: HNSW for fast similarity search
-- =====================================================

-- Pattern embeddings index (cosine distance)
CREATE INDEX IF NOT EXISTS idx_pattern_embeddings_hnsw
ON ai_pattern_embeddings
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- Document embeddings index
CREATE INDEX IF NOT EXISTS idx_document_embeddings_hnsw
ON ai_document_embeddings
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- Message embeddings index (for historical analysis)
CREATE INDEX IF NOT EXISTS idx_message_embeddings_hnsw
ON ai_message_embeddings
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- =====================================================
-- INDEXES: Filtering indexes
-- =====================================================

-- Pattern filtering
CREATE INDEX IF NOT EXISTS idx_pattern_embeddings_tenant
ON ai_pattern_embeddings(tenant_id);

CREATE INDEX IF NOT EXISTS idx_pattern_embeddings_type
ON ai_pattern_embeddings(tenant_id, pattern_type);

-- Document filtering
CREATE INDEX IF NOT EXISTS idx_document_embeddings_tenant
ON ai_document_embeddings(tenant_id);

CREATE INDEX IF NOT EXISTS idx_document_embeddings_type
ON ai_document_embeddings(tenant_id, document_type);

CREATE INDEX IF NOT EXISTS idx_document_embeddings_active
ON ai_document_embeddings(tenant_id, is_active);

-- GIN index for tags array search
CREATE INDEX IF NOT EXISTS idx_document_embeddings_tags
ON ai_document_embeddings USING GIN(tags);

-- Message filtering
CREATE INDEX IF NOT EXISTS idx_message_embeddings_tenant
ON ai_message_embeddings(tenant_id);

CREATE INDEX IF NOT EXISTS idx_message_embeddings_conversation
ON ai_message_embeddings(conversation_id);

CREATE INDEX IF NOT EXISTS idx_message_embeddings_intent
ON ai_message_embeddings(tenant_id, classified_intent);

-- =====================================================
-- ROW LEVEL SECURITY
-- =====================================================

ALTER TABLE ai_pattern_embeddings ENABLE ROW LEVEL SECURITY;
ALTER TABLE ai_document_embeddings ENABLE ROW LEVEL SECURITY;
ALTER TABLE ai_message_embeddings ENABLE ROW LEVEL SECURITY;

-- Pattern embeddings RLS
CREATE POLICY "Pattern embeddings tenant isolation" ON ai_pattern_embeddings
  FOR ALL USING (
    tenant_id IN (
      SELECT tenant_id FROM user_roles WHERE user_id = auth.uid()
    )
  );

-- Document embeddings RLS
CREATE POLICY "Document embeddings tenant isolation" ON ai_document_embeddings
  FOR ALL USING (
    tenant_id IN (
      SELECT tenant_id FROM user_roles WHERE user_id = auth.uid()
    )
  );

-- Message embeddings RLS
CREATE POLICY "Message embeddings tenant isolation" ON ai_message_embeddings
  FOR ALL USING (
    tenant_id IN (
      SELECT tenant_id FROM user_roles WHERE user_id = auth.uid()
    )
  );

-- Service role bypass
CREATE POLICY "Service role pattern embeddings" ON ai_pattern_embeddings
  FOR ALL TO service_role USING (true);

CREATE POLICY "Service role document embeddings" ON ai_document_embeddings
  FOR ALL TO service_role USING (true);

CREATE POLICY "Service role message embeddings" ON ai_message_embeddings
  FOR ALL TO service_role USING (true);

-- =====================================================
-- FUNCTIONS: Similarity search
-- =====================================================

-- Function: Search similar patterns
CREATE OR REPLACE FUNCTION search_similar_patterns(
  p_tenant_id UUID,
  p_query_embedding VECTOR(1536),
  p_pattern_types TEXT[] DEFAULT NULL,
  p_limit INTEGER DEFAULT 10,
  p_threshold FLOAT DEFAULT 0.7
)
RETURNS TABLE (
  pattern_id UUID,
  pattern_type TEXT,
  pattern_text TEXT,
  similarity FLOAT
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    pe.pattern_id,
    pe.pattern_type,
    pe.pattern_text,
    1 - (pe.embedding <=> p_query_embedding) AS similarity
  FROM ai_pattern_embeddings pe
  WHERE pe.tenant_id = p_tenant_id
    AND (p_pattern_types IS NULL OR pe.pattern_type = ANY(p_pattern_types))
    AND 1 - (pe.embedding <=> p_query_embedding) >= p_threshold
  ORDER BY pe.embedding <=> p_query_embedding
  LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;

-- Function: Search similar documents
CREATE OR REPLACE FUNCTION search_similar_documents(
  p_tenant_id UUID,
  p_query_embedding VECTOR(1536),
  p_document_types TEXT[] DEFAULT NULL,
  p_tags TEXT[] DEFAULT NULL,
  p_limit INTEGER DEFAULT 5,
  p_threshold FLOAT DEFAULT 0.6
)
RETURNS TABLE (
  document_id UUID,
  document_type TEXT,
  document_title TEXT,
  document_content TEXT,
  chunk_index INTEGER,
  similarity FLOAT,
  metadata JSONB
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    de.document_id,
    de.document_type,
    de.document_title,
    de.document_content,
    de.chunk_index,
    1 - (de.embedding <=> p_query_embedding) AS similarity,
    de.metadata
  FROM ai_document_embeddings de
  WHERE de.tenant_id = p_tenant_id
    AND de.is_active = TRUE
    AND (p_document_types IS NULL OR de.document_type = ANY(p_document_types))
    AND (p_tags IS NULL OR de.tags && p_tags)
    AND 1 - (de.embedding <=> p_query_embedding) >= p_threshold
  ORDER BY de.embedding <=> p_query_embedding
  LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;

-- Function: Find duplicate messages
CREATE OR REPLACE FUNCTION find_similar_messages(
  p_tenant_id UUID,
  p_query_embedding VECTOR(1536),
  p_limit INTEGER DEFAULT 10,
  p_threshold FLOAT DEFAULT 0.9
)
RETURNS TABLE (
  message_id UUID,
  conversation_id UUID,
  message_text TEXT,
  similarity FLOAT,
  message_timestamp TIMESTAMPTZ
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    me.message_id,
    me.conversation_id,
    me.message_text,
    1 - (me.embedding <=> p_query_embedding) AS similarity,
    me.message_timestamp
  FROM ai_message_embeddings me
  WHERE me.tenant_id = p_tenant_id
    AND 1 - (me.embedding <=> p_query_embedding) >= p_threshold
  ORDER BY me.embedding <=> p_query_embedding
  LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;

-- =====================================================
-- TRIGGERS: Auto-update timestamps
-- =====================================================

CREATE OR REPLACE FUNCTION update_embedding_timestamp()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = NOW();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_pattern_embedding_updated
  BEFORE UPDATE ON ai_pattern_embeddings
  FOR EACH ROW EXECUTE FUNCTION update_embedding_timestamp();

CREATE TRIGGER trigger_document_embedding_updated
  BEFORE UPDATE ON ai_document_embeddings
  FOR EACH ROW EXECUTE FUNCTION update_embedding_timestamp();
```

---

## ğŸ“Š Indexing Strategy

### HNSW Configuration

```sql
-- HNSW Parameters explanation:
-- m: Maximum number of connections per layer (higher = more accurate, more memory)
-- ef_construction: Size of dynamic candidate list during index construction

-- For patterns (medium accuracy, fast)
CREATE INDEX idx_patterns_hnsw ON ai_pattern_embeddings
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- For documents (high accuracy, slower)
CREATE INDEX idx_documents_hnsw ON ai_document_embeddings
USING hnsw (embedding vector_cosine_ops)
WITH (m = 24, ef_construction = 100);
```

### Query-time Parameters

```sql
-- Set search parameters before query
SET hnsw.ef_search = 100;  -- Higher = more accurate, slower

-- Then run query
SELECT * FROM search_similar_patterns(...);
```

### Index Maintenance

```sql
-- Reindex periodically for optimal performance
REINDEX INDEX CONCURRENTLY idx_pattern_embeddings_hnsw;

-- Analyze table for query planner
ANALYZE ai_pattern_embeddings;
```

---

## ğŸ’» ImplementaciÃ³n

### Archivo: `src/features/ai/embeddings/types/vector-store.types.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Vector Store Types
// Tipos para el almacenamiento de vectores
// =====================================================

export interface PatternEmbedding {
  id: string;
  tenant_id: string;
  pattern_id: string | null;
  pattern_type: string;
  pattern_text: string;
  embedding: number[];
  model: string;
  token_count: number;
  created_at: string;
  updated_at: string;
}

export interface DocumentEmbedding {
  id: string;
  tenant_id: string;
  document_type: 'faq' | 'policy' | 'service' | 'menu_item' | 'custom';
  document_id: string | null;
  document_title: string;
  document_content: string;
  chunk_index: number;
  chunk_start: number;
  chunk_end: number | null;
  total_chunks: number;
  embedding: number[];
  model: string;
  token_count: number;
  metadata: Record<string, unknown>;
  tags: string[];
  is_active: boolean;
  created_at: string;
  updated_at: string;
}

export interface MessageEmbedding {
  id: string;
  tenant_id: string;
  message_id: string;
  conversation_id: string | null;
  message_text: string;
  message_role: 'user' | 'assistant';
  embedding: number[];
  model: string;
  classified_intent: string | null;
  classification_confidence: number | null;
  message_timestamp: string | null;
  created_at: string;
}

export interface SimilaritySearchResult<T> {
  item: T;
  similarity: number;
}

export interface PatternSearchOptions {
  tenant_id: string;
  pattern_types?: string[];
  limit?: number;
  threshold?: number;
}

export interface DocumentSearchOptions {
  tenant_id: string;
  document_types?: string[];
  tags?: string[];
  limit?: number;
  threshold?: number;
  include_inactive?: boolean;
}

export interface MessageSearchOptions {
  tenant_id: string;
  conversation_id?: string;
  limit?: number;
  threshold?: number;
  time_range?: {
    start: Date;
    end: Date;
  };
}

export interface VectorStoreStats {
  tenant_id: string;
  pattern_count: number;
  document_count: number;
  message_count: number;
  total_vectors: number;
  avg_similarity_search_ms: number;
  index_size_mb: number;
}
```

### Archivo: `src/features/ai/embeddings/services/vector-store.service.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Vector Store Service
// Servicio para gestiÃ³n de vectores en PostgreSQL/pgvector
// =====================================================

import { createClient, SupabaseClient } from '@supabase/supabase-js';
import {
  PatternEmbedding,
  DocumentEmbedding,
  MessageEmbedding,
  SimilaritySearchResult,
  PatternSearchOptions,
  DocumentSearchOptions,
  MessageSearchOptions,
  VectorStoreStats,
} from '../types/vector-store.types';
import { EmbeddingService, embeddingService } from './embedding.service';

export class VectorStoreService {
  private supabase: SupabaseClient;
  private embeddingService: EmbeddingService;

  constructor(embeddingSvc?: EmbeddingService) {
    this.supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!
    );
    this.embeddingService = embeddingSvc ?? embeddingService;
  }

  // ==================== Pattern Operations ====================

  /**
   * Store a pattern embedding
   */
  async storePatternEmbedding(
    tenantId: string,
    patternType: string,
    patternText: string,
    patternId?: string
  ): Promise<PatternEmbedding> {
    // Generate embedding
    const result = await this.embeddingService.embed({ text: patternText });

    const record = {
      tenant_id: tenantId,
      pattern_id: patternId,
      pattern_type: patternType,
      pattern_text: patternText,
      embedding: `[${result.embedding.join(',')}]`, // pgvector format
      model: result.model,
      token_count: result.tokenCount,
    };

    const { data, error } = await this.supabase
      .from('ai_pattern_embeddings')
      .upsert(record, {
        onConflict: 'tenant_id,pattern_id',
      })
      .select()
      .single();

    if (error) throw error;
    return this.parsePatternEmbedding(data);
  }

  /**
   * Search for similar patterns
   */
  async searchSimilarPatterns(
    queryText: string,
    options: PatternSearchOptions
  ): Promise<SimilaritySearchResult<PatternEmbedding>[]> {
    // Generate query embedding
    const queryResult = await this.embeddingService.embed({ text: queryText });

    // Call search function
    const { data, error } = await this.supabase.rpc('search_similar_patterns', {
      p_tenant_id: options.tenant_id,
      p_query_embedding: `[${queryResult.embedding.join(',')}]`,
      p_pattern_types: options.pattern_types ?? null,
      p_limit: options.limit ?? 10,
      p_threshold: options.threshold ?? 0.7,
    });

    if (error) throw error;

    return (data || []).map((row: { pattern_id: string; pattern_type: string; pattern_text: string; similarity: number }) => ({
      item: {
        pattern_id: row.pattern_id,
        pattern_type: row.pattern_type,
        pattern_text: row.pattern_text,
      } as PatternEmbedding,
      similarity: row.similarity,
    }));
  }

  /**
   * Batch store pattern embeddings
   */
  async batchStorePatterns(
    tenantId: string,
    patterns: Array<{ type: string; text: string; id?: string }>
  ): Promise<number> {
    // Generate embeddings in batch
    const batchResult = await this.embeddingService.embedBatch({
      texts: patterns.map(p => p.text),
    });

    // Prepare records
    const records = patterns.map((pattern, index) => ({
      tenant_id: tenantId,
      pattern_id: pattern.id,
      pattern_type: pattern.type,
      pattern_text: pattern.text,
      embedding: `[${batchResult.results[index].embedding.join(',')}]`,
      model: batchResult.results[index].model,
      token_count: batchResult.results[index].tokenCount,
    }));

    // Batch insert
    const { error } = await this.supabase
      .from('ai_pattern_embeddings')
      .upsert(records, { onConflict: 'tenant_id,pattern_id' });

    if (error) throw error;
    return records.length;
  }

  // ==================== Document Operations ====================

  /**
   * Store a document embedding (with chunking support)
   */
  async storeDocumentEmbedding(
    tenantId: string,
    document: {
      type: string;
      id?: string;
      title: string;
      content: string;
      metadata?: Record<string, unknown>;
      tags?: string[];
    }
  ): Promise<DocumentEmbedding[]> {
    const { createTextChunks } = await import('../utils/text-preprocessor');

    // Chunk document if needed
    const chunks = createTextChunks(document.content, 1000, 100);
    const results: DocumentEmbedding[] = [];

    // Generate embeddings for all chunks
    const batchResult = await this.embeddingService.embedBatch({
      texts: chunks.map(c => c.text),
    });

    // Store each chunk
    for (let i = 0; i < chunks.length; i++) {
      const record = {
        tenant_id: tenantId,
        document_type: document.type,
        document_id: document.id,
        document_title: document.title,
        document_content: chunks[i].text,
        chunk_index: i,
        chunk_start: chunks[i].startIndex,
        chunk_end: chunks[i].endIndex,
        total_chunks: chunks.length,
        embedding: `[${batchResult.results[i].embedding.join(',')}]`,
        model: batchResult.results[i].model,
        token_count: batchResult.results[i].tokenCount,
        metadata: document.metadata ?? {},
        tags: document.tags ?? [],
      };

      const { data, error } = await this.supabase
        .from('ai_document_embeddings')
        .insert(record)
        .select()
        .single();

      if (error) throw error;
      results.push(this.parseDocumentEmbedding(data));
    }

    return results;
  }

  /**
   * Search for similar documents
   */
  async searchSimilarDocuments(
    queryText: string,
    options: DocumentSearchOptions
  ): Promise<SimilaritySearchResult<DocumentEmbedding>[]> {
    const queryResult = await this.embeddingService.embed({ text: queryText });

    const { data, error } = await this.supabase.rpc('search_similar_documents', {
      p_tenant_id: options.tenant_id,
      p_query_embedding: `[${queryResult.embedding.join(',')}]`,
      p_document_types: options.document_types ?? null,
      p_tags: options.tags ?? null,
      p_limit: options.limit ?? 5,
      p_threshold: options.threshold ?? 0.6,
    });

    if (error) throw error;

    return (data || []).map((row: {
      document_id: string;
      document_type: string;
      document_title: string;
      document_content: string;
      chunk_index: number;
      similarity: number;
      metadata: Record<string, unknown>;
    }) => ({
      item: {
        document_id: row.document_id,
        document_type: row.document_type,
        document_title: row.document_title,
        document_content: row.document_content,
        chunk_index: row.chunk_index,
        metadata: row.metadata,
      } as DocumentEmbedding,
      similarity: row.similarity,
    }));
  }

  /**
   * Update document status
   */
  async setDocumentActive(
    tenantId: string,
    documentId: string,
    isActive: boolean
  ): Promise<void> {
    const { error } = await this.supabase
      .from('ai_document_embeddings')
      .update({ is_active: isActive, updated_at: new Date().toISOString() })
      .eq('tenant_id', tenantId)
      .eq('document_id', documentId);

    if (error) throw error;
  }

  // ==================== Message Operations ====================

  /**
   * Store a message embedding for analysis
   */
  async storeMessageEmbedding(
    tenantId: string,
    message: {
      messageId: string;
      conversationId?: string;
      text: string;
      role: 'user' | 'assistant';
      timestamp?: Date;
    }
  ): Promise<MessageEmbedding> {
    const result = await this.embeddingService.embed({ text: message.text });

    const record = {
      tenant_id: tenantId,
      message_id: message.messageId,
      conversation_id: message.conversationId,
      message_text: message.text,
      message_role: message.role,
      embedding: `[${result.embedding.join(',')}]`,
      model: result.model,
      message_timestamp: message.timestamp?.toISOString(),
    };

    const { data, error } = await this.supabase
      .from('ai_message_embeddings')
      .insert(record)
      .select()
      .single();

    if (error) throw error;
    return this.parseMessageEmbedding(data);
  }

  /**
   * Find similar historical messages
   */
  async findSimilarMessages(
    queryText: string,
    options: MessageSearchOptions
  ): Promise<SimilaritySearchResult<MessageEmbedding>[]> {
    const queryResult = await this.embeddingService.embed({ text: queryText });

    const { data, error } = await this.supabase.rpc('find_similar_messages', {
      p_tenant_id: options.tenant_id,
      p_query_embedding: `[${queryResult.embedding.join(',')}]`,
      p_limit: options.limit ?? 10,
      p_threshold: options.threshold ?? 0.9,
    });

    if (error) throw error;

    return (data || []).map((row: {
      message_id: string;
      conversation_id: string;
      message_text: string;
      similarity: number;
      message_timestamp: string;
    }) => ({
      item: {
        message_id: row.message_id,
        conversation_id: row.conversation_id,
        message_text: row.message_text,
        message_timestamp: row.message_timestamp,
      } as MessageEmbedding,
      similarity: row.similarity,
    }));
  }

  /**
   * Update message classification
   */
  async updateMessageClassification(
    messageId: string,
    intent: string,
    confidence: number
  ): Promise<void> {
    const { error } = await this.supabase
      .from('ai_message_embeddings')
      .update({
        classified_intent: intent,
        classification_confidence: confidence,
      })
      .eq('message_id', messageId);

    if (error) throw error;
  }

  // ==================== Utility Methods ====================

  /**
   * Get vector store statistics
   */
  async getStats(tenantId: string): Promise<VectorStoreStats> {
    const [patterns, documents, messages] = await Promise.all([
      this.supabase
        .from('ai_pattern_embeddings')
        .select('*', { count: 'exact', head: true })
        .eq('tenant_id', tenantId),
      this.supabase
        .from('ai_document_embeddings')
        .select('*', { count: 'exact', head: true })
        .eq('tenant_id', tenantId),
      this.supabase
        .from('ai_message_embeddings')
        .select('*', { count: 'exact', head: true })
        .eq('tenant_id', tenantId),
    ]);

    return {
      tenant_id: tenantId,
      pattern_count: patterns.count ?? 0,
      document_count: documents.count ?? 0,
      message_count: messages.count ?? 0,
      total_vectors: (patterns.count ?? 0) + (documents.count ?? 0) + (messages.count ?? 0),
      avg_similarity_search_ms: 0, // Would need to measure
      index_size_mb: 0, // Would need pg_indexes_size query
    };
  }

  /**
   * Delete all embeddings for a tenant
   */
  async deleteAllForTenant(tenantId: string): Promise<void> {
    await Promise.all([
      this.supabase.from('ai_pattern_embeddings').delete().eq('tenant_id', tenantId),
      this.supabase.from('ai_document_embeddings').delete().eq('tenant_id', tenantId),
      this.supabase.from('ai_message_embeddings').delete().eq('tenant_id', tenantId),
    ]);
  }

  // ==================== Private Helpers ====================

  private parsePatternEmbedding(data: Record<string, unknown>): PatternEmbedding {
    return {
      ...data,
      embedding: this.parseVectorString(data.embedding as string),
    } as PatternEmbedding;
  }

  private parseDocumentEmbedding(data: Record<string, unknown>): DocumentEmbedding {
    return {
      ...data,
      embedding: this.parseVectorString(data.embedding as string),
    } as DocumentEmbedding;
  }

  private parseMessageEmbedding(data: Record<string, unknown>): MessageEmbedding {
    return {
      ...data,
      embedding: this.parseVectorString(data.embedding as string),
    } as MessageEmbedding;
  }

  private parseVectorString(vectorStr: string): number[] {
    if (Array.isArray(vectorStr)) return vectorStr;
    // Parse PostgreSQL vector format: [0.1,0.2,0.3]
    const cleaned = vectorStr.replace(/[\[\]]/g, '');
    return cleaned.split(',').map(parseFloat);
  }
}

export const vectorStore = new VectorStoreService();
```

---

## ğŸ” Queries Optimizadas

### Query: BÃºsqueda HÃ­brida (SemÃ¡ntica + Keyword)

```sql
-- Combine semantic search with keyword filtering
CREATE OR REPLACE FUNCTION hybrid_document_search(
  p_tenant_id UUID,
  p_query_embedding VECTOR(1536),
  p_keyword TEXT,
  p_limit INTEGER DEFAULT 10
)
RETURNS TABLE (
  document_id UUID,
  document_title TEXT,
  document_content TEXT,
  semantic_score FLOAT,
  keyword_score FLOAT,
  combined_score FLOAT
) AS $$
BEGIN
  RETURN QUERY
  WITH semantic AS (
    SELECT
      de.document_id,
      de.document_title,
      de.document_content,
      1 - (de.embedding <=> p_query_embedding) AS semantic_score
    FROM ai_document_embeddings de
    WHERE de.tenant_id = p_tenant_id
      AND de.is_active = TRUE
    ORDER BY de.embedding <=> p_query_embedding
    LIMIT p_limit * 2
  ),
  keyword_matched AS (
    SELECT
      document_id,
      document_title,
      document_content,
      semantic_score,
      ts_rank(
        to_tsvector('spanish', document_content),
        plainto_tsquery('spanish', p_keyword)
      ) AS keyword_score
    FROM semantic
    WHERE document_content ILIKE '%' || p_keyword || '%'
       OR document_title ILIKE '%' || p_keyword || '%'
  )
  SELECT
    document_id,
    document_title,
    document_content,
    semantic_score,
    keyword_score,
    (semantic_score * 0.7 + keyword_score * 0.3) AS combined_score
  FROM keyword_matched
  ORDER BY combined_score DESC
  LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;
```

### Query: Clustering de Mensajes Similares

```sql
-- Find clusters of similar messages
CREATE OR REPLACE FUNCTION find_message_clusters(
  p_tenant_id UUID,
  p_threshold FLOAT DEFAULT 0.85,
  p_min_cluster_size INTEGER DEFAULT 3
)
RETURNS TABLE (
  cluster_representative TEXT,
  cluster_size BIGINT,
  sample_messages TEXT[]
) AS $$
BEGIN
  RETURN QUERY
  WITH pairs AS (
    SELECT
      a.message_text AS msg_a,
      b.message_text AS msg_b,
      1 - (a.embedding <=> b.embedding) AS similarity
    FROM ai_message_embeddings a
    JOIN ai_message_embeddings b ON a.id < b.id
    WHERE a.tenant_id = p_tenant_id
      AND b.tenant_id = p_tenant_id
      AND 1 - (a.embedding <=> b.embedding) >= p_threshold
  ),
  clusters AS (
    SELECT
      msg_a AS representative,
      ARRAY_AGG(DISTINCT msg_b) AS members
    FROM pairs
    GROUP BY msg_a
    HAVING COUNT(*) >= p_min_cluster_size - 1
  )
  SELECT
    representative AS cluster_representative,
    ARRAY_LENGTH(members, 1) + 1 AS cluster_size,
    members[1:5] AS sample_messages
  FROM clusters
  ORDER BY cluster_size DESC;
END;
$$ LANGUAGE plpgsql;
```

---

## âœ… Checklist de ImplementaciÃ³n

```
â–¡ Paso 1: Database Setup
â”œâ”€â”€ [ ] Verificar pgvector enabled en Supabase
â”œâ”€â”€ [ ] Ejecutar migration 210_VECTOR_STORE.sql
â”œâ”€â”€ [ ] Verificar tablas creadas
â”œâ”€â”€ [ ] Verificar Ã­ndices HNSW creados
â””â”€â”€ [ ] Probar RLS policies

â–¡ Paso 2: Implementar Types
â”œâ”€â”€ [ ] Crear vector-store.types.ts
â”œâ”€â”€ [ ] Definir interfaces
â””â”€â”€ [ ] Exportar tipos

â–¡ Paso 3: Implementar Service
â”œâ”€â”€ [ ] Crear VectorStoreService
â”œâ”€â”€ [ ] Pattern operations
â”œâ”€â”€ [ ] Document operations
â”œâ”€â”€ [ ] Message operations
â”œâ”€â”€ [ ] Utility methods
â””â”€â”€ [ ] Unit tests

â–¡ Paso 4: Optimizaciones
â”œâ”€â”€ [ ] Implementar hybrid search
â”œâ”€â”€ [ ] Configurar HNSW parameters
â”œâ”€â”€ [ ] Agregar Ã­ndices adicionales
â””â”€â”€ [ ] Performance testing

â–¡ Paso 5: ValidaciÃ³n
â”œâ”€â”€ [ ] Test con datos reales
â”œâ”€â”€ [ ] Benchmark similarity search
â”œâ”€â”€ [ ] Verificar aislamiento de tenant
â””â”€â”€ [ ] Documentar queries SQL
```

### Comandos de VerificaciÃ³n

```bash
# Verificar pgvector instalado
psql -c "SELECT * FROM pg_extension WHERE extname = 'vector';"

# Verificar tablas creadas
psql -c "SELECT table_name FROM information_schema.tables WHERE table_name LIKE 'ai_%embedding%';"

# Verificar Ã­ndices HNSW
psql -c "SELECT indexname, indexdef FROM pg_indexes WHERE indexname LIKE '%hnsw%';"

# Test similarity search
psql -c "SELECT * FROM search_similar_patterns('tenant-id', '[0.1,0.2,...]'::vector, NULL, 5, 0.7);"
```

---

**Siguiente documento:** [2.3-SEMANTIC-SEARCH.md](./2.3-SEMANTIC-SEARCH.md)
