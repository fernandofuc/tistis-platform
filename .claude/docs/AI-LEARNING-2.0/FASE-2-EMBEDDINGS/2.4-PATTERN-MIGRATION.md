# ğŸ”„ FASE 2.4: Pattern Migration

## MigraciÃ³n de Regex a Embeddings SemÃ¡nticos

**Documento:** 2.4-PATTERN-MIGRATION.md
**Fase:** 2 - Embeddings SemÃ¡nticos
**DuraciÃ³n estimada:** 1-1.5 semanas
**Dependencias:** 2.1, 2.2, 2.3

---

## ğŸ“‹ Ãndice

1. [Objetivo](#objetivo)
2. [Estrategia de MigraciÃ³n](#estrategia-de-migraciÃ³n)
3. [Mapeo de Patrones](#mapeo-de-patrones)
4. [Proceso de MigraciÃ³n](#proceso-de-migraciÃ³n)
5. [Scripts de MigraciÃ³n](#scripts-de-migraciÃ³n)
6. [Rollback Strategy](#rollback-strategy)
7. [Checklist de ImplementaciÃ³n](#checklist-de-implementaciÃ³n)

---

## ğŸ¯ Objetivo

Migrar el sistema actual basado en regex patterns a embeddings semÃ¡nticos, manteniendo compatibilidad hacia atrÃ¡s y permitiendo rollback en caso de problemas.

### Estado Actual vs Target

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MIGRATION OVERVIEW                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  CURRENT STATE (Regex-based)                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  message-learning.service.ts                             â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ PATTERN_DEFINITIONS (regex arrays)                  â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ detectPatterns() â†’ regex matching                   â”‚   â”‚
â”‚  â”‚  â””â”€â”€ ~70% accuracy                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚                         â–¼ MIGRATE â–¼                             â”‚
â”‚                                                                  â”‚
â”‚  TARGET STATE (Embedding-based)                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  semantic-search.service.ts                              â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ INTENT_DEFINITIONS (semantic examples)              â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ classify() â†’ embedding similarity                   â”‚   â”‚
â”‚  â”‚  â””â”€â”€ >90% accuracy                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚  HYBRID PHASE (Both systems)                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  pattern-hybrid.service.ts                               â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Primary: Semantic (embeddings)                      â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Fallback: Regex (patterns)                         â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ A/B testing capability                              â”‚   â”‚
â”‚  â”‚  â””â”€â”€ Gradual rollout                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Estrategia de MigraciÃ³n

### Fases de MigraciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MIGRATION PHASES                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Phase 1: SHADOW MODE (1 week)                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  â€¢ Run both systems in parallel                              â”‚  â”‚
â”‚  â”‚  â€¢ Regex remains primary                                     â”‚  â”‚
â”‚  â”‚  â€¢ Log semantic results for comparison                       â”‚  â”‚
â”‚  â”‚  â€¢ Collect accuracy metrics                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â–¼                                      â”‚
â”‚  Phase 2: A/B TEST (2 weeks)                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  â€¢ 20% traffic â†’ semantic                                    â”‚  â”‚
â”‚  â”‚  â€¢ 80% traffic â†’ regex                                       â”‚  â”‚
â”‚  â”‚  â€¢ Monitor RLHF feedback                                     â”‚  â”‚
â”‚  â”‚  â€¢ Compare satisfaction rates                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â–¼                                      â”‚
â”‚  Phase 3: GRADUAL ROLLOUT (2 weeks)                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  â€¢ Week 1: 50% semantic                                      â”‚  â”‚
â”‚  â”‚  â€¢ Week 2: 80% semantic                                      â”‚  â”‚
â”‚  â”‚  â€¢ Continue monitoring                                       â”‚  â”‚
â”‚  â”‚  â€¢ Regex as fallback                                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â–¼                                      â”‚
â”‚  Phase 4: FULL SEMANTIC (ongoing)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  â€¢ 100% semantic primary                                     â”‚  â”‚
â”‚  â”‚  â€¢ Regex disabled (kept for emergency rollback)             â”‚  â”‚
â”‚  â”‚  â€¢ Archive regex code                                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Feature Flags

```typescript
// Feature flag configuration
const MIGRATION_FLAGS = {
  // Master switch
  SEMANTIC_ENABLED: true,

  // Phase control
  SHADOW_MODE: false,      // Log only, don't use semantic results
  AB_TEST_ENABLED: false,  // Enable A/B testing
  AB_TEST_RATIO: 0.2,      // % of traffic to semantic

  // Rollout control
  SEMANTIC_RATIO: 1.0,     // % of traffic using semantic (post A/B)

  // Fallback behavior
  USE_REGEX_FALLBACK: true, // Fall back to regex if semantic fails
  FALLBACK_THRESHOLD: 0.5,  // Min confidence for semantic to be used
};
```

---

## ğŸ—ºï¸ Mapeo de Patrones

### Regex Pattern â†’ Intent Mapping

```typescript
// Current regex patterns in message-learning.service.ts
const CURRENT_PATTERNS = {
  service_request: [
    /quiero.*cita/i,
    /necesito.*turno/i,
    /reservar/i,
    /agendar/i,
  ],
  pricing_inquiry: [
    /cuanto.*cuesta/i,
    /precio/i,
    /valor/i,
    /tarifa/i,
  ],
  // ... more patterns
};

// Mapping to semantic intents
const PATTERN_TO_INTENT_MAP: Record<string, string> = {
  'service_request': 'scheduling',
  'pricing_inquiry': 'pricing',
  'scheduling_preference': 'scheduling',
  'pain_point': 'complaint',
  'objection': 'complaint',
  'competitor_mention': 'inquiry',
  'satisfaction': 'feedback',
  'complaint': 'complaint',
  'referral': 'feedback',
  'vocabulary': 'inquiry',
  'question_pattern': 'inquiry',
  'booking_behavior': 'scheduling',
  'follow_up_need': 'inquiry',
  'urgency_indicator': 'scheduling',
};
```

### MigraciÃ³n de Ejemplos

```typescript
// Convert regex patterns to semantic examples
const MIGRATION_EXAMPLES: Record<string, string[]> = {
  'service_request â†’ scheduling': [
    // From regex /quiero.*cita/
    'Quiero una cita',
    'Quiero agendar una cita',
    'Quiero pedir hora',
    // From regex /necesito.*turno/
    'Necesito un turno',
    'Necesito turno urgente',
    // From regex /reservar/
    'Reservar hora',
    'Quiero reservar',
    // From regex /agendar/
    'Agendar cita',
    'Me gustarÃ­a agendar',
  ],
  'pricing_inquiry â†’ pricing': [
    // From regex /cuanto.*cuesta/
    'CuÃ¡nto cuesta la consulta',
    'CuÃ¡nto cuesta el tratamiento',
    // From regex /precio/
    'CuÃ¡l es el precio',
    'Precio de la cita',
    // etc.
  ],
};
```

---

## ğŸ”§ Proceso de MigraciÃ³n

### Paso 1: Exportar Patrones Actuales

```typescript
// scripts/export-patterns.ts
import { PATTERN_DEFINITIONS } from '../src/features/ai/services/message-learning.service';
import fs from 'fs';

async function exportPatterns() {
  const output: Record<string, {
    regexPatterns: string[];
    exampleMatches: string[];
  }> = {};

  for (const [patternType, patterns] of Object.entries(PATTERN_DEFINITIONS)) {
    output[patternType] = {
      regexPatterns: patterns.map(p => p.toString()),
      exampleMatches: [], // Will be filled from historical data
    };
  }

  // Export to JSON for review
  fs.writeFileSync(
    'migration/pattern-export.json',
    JSON.stringify(output, null, 2)
  );

  console.log('Patterns exported to migration/pattern-export.json');
}

exportPatterns();
```

### Paso 2: Generar Ejemplos de Entrenamiento

```typescript
// scripts/generate-training-examples.ts
import { createClient } from '@supabase/supabase-js';

async function generateTrainingExamples() {
  const supabase = createClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_ROLE_KEY!
  );

  // Get historical messages that matched each pattern type
  const { data: patterns } = await supabase
    .from('ai_message_patterns')
    .select('pattern_type, pattern_value, context_examples')
    .order('occurrence_count', { ascending: false });

  const trainingData: Record<string, string[]> = {};

  for (const pattern of patterns || []) {
    const intentType = PATTERN_TO_INTENT_MAP[pattern.pattern_type] || 'unknown';

    if (!trainingData[intentType]) {
      trainingData[intentType] = [];
    }

    // Add the pattern value itself
    trainingData[intentType].push(pattern.pattern_value);

    // Add context examples
    if (pattern.context_examples) {
      trainingData[intentType].push(...pattern.context_examples);
    }
  }

  // Deduplicate and export
  for (const intent of Object.keys(trainingData)) {
    trainingData[intent] = [...new Set(trainingData[intent])];
  }

  return trainingData;
}
```

### Paso 3: Crear Embeddings para Patrones Existentes

```typescript
// scripts/create-pattern-embeddings.ts
import { embeddingService } from '../src/features/ai/embeddings/services/embedding.service';
import { vectorStore } from '../src/features/ai/embeddings/services/vector-store.service';

async function createPatternEmbeddings(tenantId: string) {
  const supabase = createClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_ROLE_KEY!
  );

  // Get all active patterns for tenant
  const { data: patterns } = await supabase
    .from('ai_message_patterns')
    .select('id, pattern_type, pattern_value')
    .eq('tenant_id', tenantId)
    .eq('is_active', true);

  if (!patterns || patterns.length === 0) {
    console.log('No patterns to migrate');
    return;
  }

  console.log(`Migrating ${patterns.length} patterns...`);

  // Batch create embeddings
  const patternData = patterns.map(p => ({
    id: p.id,
    type: PATTERN_TO_INTENT_MAP[p.pattern_type] || p.pattern_type,
    text: p.pattern_value,
  }));

  const migrated = await vectorStore.batchStorePatterns(tenantId, patternData);

  console.log(`Successfully migrated ${migrated} patterns to embeddings`);

  return migrated;
}
```

---

## ğŸ’» Scripts de MigraciÃ³n

### Archivo: `scripts/migration/migrate-patterns.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Pattern Migration Script
// Migra patrones de regex a embeddings semÃ¡nticos
// =====================================================

import { createClient, SupabaseClient } from '@supabase/supabase-js';
import { VectorStoreService } from '../../src/features/ai/embeddings/services/vector-store.service';
import { EmbeddingService } from '../../src/features/ai/embeddings/services/embedding.service';
import { INTENT_DEFINITIONS } from '../../src/features/ai/semantic/services/intent-classifier.service';

// Pattern type to intent mapping
const PATTERN_TO_INTENT: Record<string, string> = {
  'service_request': 'scheduling',
  'pricing_inquiry': 'pricing',
  'scheduling_preference': 'scheduling',
  'pain_point': 'complaint',
  'objection': 'complaint',
  'competitor_mention': 'inquiry',
  'satisfaction': 'feedback',
  'complaint': 'complaint',
  'referral': 'feedback',
  'vocabulary': 'inquiry',
  'question_pattern': 'inquiry',
  'booking_behavior': 'scheduling',
  'follow_up_need': 'inquiry',
  'urgency_indicator': 'scheduling',
};

interface MigrationStats {
  tenant_id: string;
  patterns_processed: number;
  patterns_migrated: number;
  patterns_skipped: number;
  embeddings_created: number;
  errors: string[];
  duration_ms: number;
}

interface MigrationOptions {
  tenantId?: string;
  dryRun?: boolean;
  batchSize?: number;
  skipExisting?: boolean;
}

export class PatternMigration {
  private supabase: SupabaseClient;
  private vectorStore: VectorStoreService;
  private embeddingService: EmbeddingService;

  constructor() {
    this.supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!
    );
    this.vectorStore = new VectorStoreService();
    this.embeddingService = new EmbeddingService();
  }

  /**
   * Run migration for a single tenant
   */
  async migrateTenant(tenantId: string, options: MigrationOptions = {}): Promise<MigrationStats> {
    const startTime = Date.now();
    const stats: MigrationStats = {
      tenant_id: tenantId,
      patterns_processed: 0,
      patterns_migrated: 0,
      patterns_skipped: 0,
      embeddings_created: 0,
      errors: [],
      duration_ms: 0,
    };

    try {
      // 1. Fetch existing patterns
      const { data: patterns, error } = await this.supabase
        .from('ai_message_patterns')
        .select('*')
        .eq('tenant_id', tenantId)
        .eq('is_active', true);

      if (error) throw error;
      if (!patterns || patterns.length === 0) {
        console.log(`[Migration] No patterns found for tenant ${tenantId}`);
        return stats;
      }

      stats.patterns_processed = patterns.length;
      console.log(`[Migration] Processing ${patterns.length} patterns for tenant ${tenantId}`);

      // 2. Check for existing embeddings
      const { data: existingEmbeddings } = await this.supabase
        .from('ai_pattern_embeddings')
        .select('pattern_id')
        .eq('tenant_id', tenantId);

      const existingPatternIds = new Set(
        existingEmbeddings?.map(e => e.pattern_id) ?? []
      );

      // 3. Filter patterns to migrate
      const toMigrate = options.skipExisting
        ? patterns.filter(p => !existingPatternIds.has(p.id))
        : patterns;

      stats.patterns_skipped = patterns.length - toMigrate.length;

      if (options.dryRun) {
        console.log(`[Migration] DRY RUN - Would migrate ${toMigrate.length} patterns`);
        stats.patterns_migrated = toMigrate.length;
        stats.duration_ms = Date.now() - startTime;
        return stats;
      }

      // 4. Batch process patterns
      const batchSize = options.batchSize ?? 50;

      for (let i = 0; i < toMigrate.length; i += batchSize) {
        const batch = toMigrate.slice(i, i + batchSize);

        const patternData = batch.map(p => ({
          id: p.id,
          type: PATTERN_TO_INTENT[p.pattern_type] || p.pattern_type,
          text: p.pattern_value,
        }));

        try {
          const created = await this.vectorStore.batchStorePatterns(tenantId, patternData);
          stats.embeddings_created += created;
          stats.patterns_migrated += batch.length;

          console.log(`[Migration] Batch ${Math.floor(i / batchSize) + 1}: ${created} embeddings created`);
        } catch (batchError) {
          stats.errors.push(`Batch ${i}-${i + batchSize}: ${batchError}`);
          console.error(`[Migration] Batch error:`, batchError);
        }
      }

      // 5. Create base intent embeddings
      await this.createBaseIntentEmbeddings(tenantId);

    } catch (error) {
      stats.errors.push(error instanceof Error ? error.message : String(error));
      console.error(`[Migration] Error for tenant ${tenantId}:`, error);
    }

    stats.duration_ms = Date.now() - startTime;
    return stats;
  }

  /**
   * Create embeddings for base intent examples
   */
  private async createBaseIntentEmbeddings(tenantId: string): Promise<void> {
    console.log(`[Migration] Creating base intent embeddings for tenant ${tenantId}`);

    for (const intent of INTENT_DEFINITIONS) {
      const patternData = intent.examples.map((example, idx) => ({
        id: `base_${intent.intent}_${idx}`,
        type: intent.intent,
        text: example,
      }));

      await this.vectorStore.batchStorePatterns(tenantId, patternData);
    }
  }

  /**
   * Run migration for all tenants
   */
  async migrateAllTenants(options: MigrationOptions = {}): Promise<MigrationStats[]> {
    const { data: tenants } = await this.supabase
      .from('ai_learning_config')
      .select('tenant_id')
      .eq('learning_enabled', true);

    const results: MigrationStats[] = [];

    for (const tenant of tenants || []) {
      const stats = await this.migrateTenant(tenant.tenant_id, options);
      results.push(stats);
    }

    return results;
  }

  /**
   * Verify migration completeness
   */
  async verifyMigration(tenantId: string): Promise<{
    total_patterns: number;
    migrated_patterns: number;
    missing_patterns: string[];
    coverage_percentage: number;
  }> {
    const { data: patterns } = await this.supabase
      .from('ai_message_patterns')
      .select('id, pattern_value')
      .eq('tenant_id', tenantId)
      .eq('is_active', true);

    const { data: embeddings } = await this.supabase
      .from('ai_pattern_embeddings')
      .select('pattern_id')
      .eq('tenant_id', tenantId);

    const patternIds = new Set(patterns?.map(p => p.id) ?? []);
    const embeddingPatternIds = new Set(embeddings?.map(e => e.pattern_id) ?? []);

    const missingIds = [...patternIds].filter(id => !embeddingPatternIds.has(id));
    const missingPatterns = patterns
      ?.filter(p => missingIds.includes(p.id))
      .map(p => p.pattern_value) ?? [];

    return {
      total_patterns: patternIds.size,
      migrated_patterns: embeddingPatternIds.size,
      missing_patterns: missingPatterns,
      coverage_percentage: patternIds.size > 0
        ? (embeddingPatternIds.size / patternIds.size) * 100
        : 100,
    };
  }
}

// CLI execution
if (require.main === module) {
  const migration = new PatternMigration();

  const args = process.argv.slice(2);
  const tenantId = args.find(a => !a.startsWith('--'));
  const dryRun = args.includes('--dry-run');
  const skipExisting = args.includes('--skip-existing');

  console.log('=== Pattern Migration ===');
  console.log(`Dry run: ${dryRun}`);
  console.log(`Skip existing: ${skipExisting}`);

  if (tenantId) {
    migration.migrateTenant(tenantId, { dryRun, skipExisting })
      .then(stats => {
        console.log('\n=== Migration Complete ===');
        console.log(JSON.stringify(stats, null, 2));
      })
      .catch(console.error);
  } else {
    migration.migrateAllTenants({ dryRun, skipExisting })
      .then(results => {
        console.log('\n=== Migration Complete ===');
        console.log(`Tenants processed: ${results.length}`);
        console.log(`Total patterns migrated: ${results.reduce((s, r) => s + r.patterns_migrated, 0)}`);
        console.log(`Total errors: ${results.reduce((s, r) => s + r.errors.length, 0)}`);
      })
      .catch(console.error);
  }
}
```

### Archivo: `scripts/migration/hybrid-classifier.ts`

```typescript
// =====================================================
// TIS TIS PLATFORM - Hybrid Pattern Classifier
// Combina regex y embeddings durante la migraciÃ³n
// =====================================================

import { PATTERN_DEFINITIONS, detectPatterns } from '../../src/features/ai/services/message-learning.service';
import { intentClassifier } from '../../src/features/ai/semantic/services/intent-classifier.service';
import { ClassificationResult } from '../../src/features/ai/semantic/types/semantic.types';

interface HybridConfig {
  mode: 'shadow' | 'ab_test' | 'semantic_primary' | 'semantic_only';
  semanticRatio: number;
  fallbackThreshold: number;
  logComparisons: boolean;
}

interface HybridResult {
  primary: {
    source: 'regex' | 'semantic';
    result: string | ClassificationResult;
  };
  comparison?: {
    regex: string[];
    semantic: ClassificationResult;
    agreement: boolean;
  };
}

export class HybridClassifier {
  private config: HybridConfig;

  constructor(config: Partial<HybridConfig> = {}) {
    this.config = {
      mode: config.mode ?? 'shadow',
      semanticRatio: config.semanticRatio ?? 0.2,
      fallbackThreshold: config.fallbackThreshold ?? 0.5,
      logComparisons: config.logComparisons ?? true,
    };
  }

  /**
   * Classify message using hybrid approach
   */
  async classify(message: string, tenantId: string): Promise<HybridResult> {
    const [regexResult, semanticResult] = await Promise.all([
      this.classifyWithRegex(message),
      intentClassifier.classify(message),
    ]);

    // Log comparison for analysis
    if (this.config.logComparisons) {
      this.logComparison(message, regexResult, semanticResult);
    }

    switch (this.config.mode) {
      case 'shadow':
        // Regex is primary, semantic logged only
        return {
          primary: { source: 'regex', result: regexResult[0] || 'unknown' },
          comparison: {
            regex: regexResult,
            semantic: semanticResult,
            agreement: this.checkAgreement(regexResult, semanticResult),
          },
        };

      case 'ab_test':
        // Randomly select based on ratio
        const useSemantics = Math.random() < this.config.semanticRatio;
        return {
          primary: useSemantics
            ? { source: 'semantic', result: semanticResult }
            : { source: 'regex', result: regexResult[0] || 'unknown' },
          comparison: {
            regex: regexResult,
            semantic: semanticResult,
            agreement: this.checkAgreement(regexResult, semanticResult),
          },
        };

      case 'semantic_primary':
        // Semantic primary with regex fallback
        if (semanticResult.confidence >= this.config.fallbackThreshold) {
          return {
            primary: { source: 'semantic', result: semanticResult },
          };
        } else {
          return {
            primary: { source: 'regex', result: regexResult[0] || 'unknown' },
            comparison: {
              regex: regexResult,
              semantic: semanticResult,
              agreement: false,
            },
          };
        }

      case 'semantic_only':
        // Semantic only, no fallback
        return {
          primary: { source: 'semantic', result: semanticResult },
        };

      default:
        throw new Error(`Unknown mode: ${this.config.mode}`);
    }
  }

  /**
   * Classify using legacy regex patterns
   */
  private async classifyWithRegex(message: string): Promise<string[]> {
    const detected: string[] = [];

    for (const [patternType, patterns] of Object.entries(PATTERN_DEFINITIONS)) {
      for (const pattern of patterns as RegExp[]) {
        if (pattern.test(message)) {
          detected.push(patternType);
          break;
        }
      }
    }

    return detected;
  }

  /**
   * Check if regex and semantic results agree
   */
  private checkAgreement(
    regexResults: string[],
    semanticResult: ClassificationResult
  ): boolean {
    const PATTERN_TO_INTENT: Record<string, string> = {
      'service_request': 'scheduling',
      'pricing_inquiry': 'pricing',
      'complaint': 'complaint',
      'satisfaction': 'feedback',
      // ... mapping
    };

    const semanticIntent = semanticResult.intent;
    const regexIntents = regexResults.map(r => PATTERN_TO_INTENT[r] || r);

    return regexIntents.includes(semanticIntent);
  }

  /**
   * Log comparison for analysis
   */
  private logComparison(
    message: string,
    regexResults: string[],
    semanticResult: ClassificationResult
  ): void {
    const agreement = this.checkAgreement(regexResults, semanticResult);

    console.log({
      timestamp: new Date().toISOString(),
      message: message.substring(0, 100),
      regex: regexResults,
      semantic: {
        intent: semanticResult.intent,
        confidence: semanticResult.confidence,
      },
      agreement,
    });

    // In production, send to analytics/logging service
    // await analytics.log('pattern_comparison', { ... });
  }

  /**
   * Get current mode
   */
  getMode(): string {
    return this.config.mode;
  }

  /**
   * Update mode dynamically
   */
  setMode(mode: HybridConfig['mode']): void {
    this.config.mode = mode;
  }

  /**
   * Update semantic ratio for A/B testing
   */
  setSemanticRatio(ratio: number): void {
    this.config.semanticRatio = Math.max(0, Math.min(1, ratio));
  }
}

export const hybridClassifier = new HybridClassifier();
```

---

## ğŸ”™ Rollback Strategy

### Rollback Plan

```typescript
// scripts/migration/rollback.ts

interface RollbackConfig {
  mode: 'soft' | 'hard';
  preserveEmbeddings: boolean;
}

export async function rollbackMigration(
  tenantId: string,
  config: RollbackConfig = { mode: 'soft', preserveEmbeddings: true }
): Promise<void> {
  console.log(`[Rollback] Starting rollback for tenant ${tenantId}`);

  // 1. Update feature flags
  await updateFeatureFlags(tenantId, {
    SEMANTIC_ENABLED: false,
    USE_REGEX_FALLBACK: true,
    SEMANTIC_RATIO: 0,
  });

  // 2. Switch classifier mode
  hybridClassifier.setMode('shadow');

  if (config.mode === 'hard') {
    if (!config.preserveEmbeddings) {
      // 3. Delete embeddings (optional)
      await supabase
        .from('ai_pattern_embeddings')
        .delete()
        .eq('tenant_id', tenantId);

      await supabase
        .from('ai_document_embeddings')
        .delete()
        .eq('tenant_id', tenantId);
    }
  }

  // 4. Restore regex-only processing in LangGraph
  await updateLangGraphConfig(tenantId, {
    classifier: 'regex',
    fallbackEnabled: false,
  });

  console.log(`[Rollback] Completed for tenant ${tenantId}`);
}

async function updateFeatureFlags(
  tenantId: string,
  flags: Record<string, boolean | number>
): Promise<void> {
  await supabase
    .from('feature_flags')
    .upsert({
      tenant_id: tenantId,
      flags,
      updated_at: new Date().toISOString(),
    });
}

async function updateLangGraphConfig(
  tenantId: string,
  config: Record<string, unknown>
): Promise<void> {
  await supabase
    .from('ai_learning_config')
    .update({
      graph_config: config,
      updated_at: new Date().toISOString(),
    })
    .eq('tenant_id', tenantId);
}
```

### Emergency Rollback Procedure

```markdown
## Emergency Rollback Procedure

### Trigger Conditions
- Satisfaction rate drops >10% within 24 hours
- Error rate exceeds 5%
- Latency increases >100ms average

### Steps

1. **Immediate (5 min)**
   ```bash
   # Disable semantic for all tenants
   npm run migration:rollback -- --all --mode=soft
   ```

2. **Verify (10 min)**
   ```bash
   # Check regex is active
   npm run health:check -- --classifier
   ```

3. **Investigate (30 min)**
   - Review logs for semantic failures
   - Check embedding API status
   - Analyze misclassifications

4. **Document (1 hour)**
   - Create incident report
   - Document root cause
   - Update migration plan
```

---

## âœ… Checklist de ImplementaciÃ³n

```
â–¡ Paso 1: PreparaciÃ³n
â”œâ”€â”€ [ ] Mapear todos los regex patterns a intents
â”œâ”€â”€ [ ] Exportar patterns actuales a JSON
â”œâ”€â”€ [ ] Generar ejemplos de training
â””â”€â”€ [ ] Revisar INTENT_DEFINITIONS

â–¡ Paso 2: Scripts de MigraciÃ³n
â”œâ”€â”€ [ ] Crear migrate-patterns.ts
â”œâ”€â”€ [ ] Crear hybrid-classifier.ts
â”œâ”€â”€ [ ] Crear rollback.ts
â”œâ”€â”€ [ ] Unit tests para scripts
â””â”€â”€ [ ] Test en staging

â–¡ Paso 3: Shadow Mode
â”œâ”€â”€ [ ] Desplegar hybrid classifier
â”œâ”€â”€ [ ] Configurar logging
â”œâ”€â”€ [ ] Monitorear comparisons
â”œâ”€â”€ [ ] Analizar accuracy
â””â”€â”€ [ ] 1 semana de datos

â–¡ Paso 4: A/B Test
â”œâ”€â”€ [ ] Configurar 20% semantic
â”œâ”€â”€ [ ] Integrar con RLHF feedback
â”œâ”€â”€ [ ] Dashboard de mÃ©tricas
â”œâ”€â”€ [ ] Comparar satisfaction
â””â”€â”€ [ ] 2 semanas de datos

â–¡ Paso 5: Gradual Rollout
â”œâ”€â”€ [ ] Incrementar a 50%
â”œâ”€â”€ [ ] Monitorear estabilidad
â”œâ”€â”€ [ ] Incrementar a 80%
â”œâ”€â”€ [ ] Preparar rollback
â””â”€â”€ [ ] 2 semanas

â–¡ Paso 6: Full Migration
â”œâ”€â”€ [ ] 100% semantic
â”œâ”€â”€ [ ] Desactivar regex
â”œâ”€â”€ [ ] Archivar cÃ³digo legacy
â”œâ”€â”€ [ ] Documentar resultados
â””â”€â”€ [ ] Cleanup
```

### Comandos de MigraciÃ³n

```bash
# Dry run for single tenant
npm run migration:patterns -- tenant-123 --dry-run

# Migrate single tenant
npm run migration:patterns -- tenant-123 --skip-existing

# Migrate all tenants
npm run migration:patterns -- --all

# Verify migration
npm run migration:verify -- tenant-123

# Rollback
npm run migration:rollback -- tenant-123 --mode=soft

# Check hybrid mode
npm run migration:status
```

---

**Siguiente documento:** [2.5-TESTING.md](./2.5-TESTING.md)
